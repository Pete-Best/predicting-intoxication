{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "#!pip install pyAudioAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "#!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore\n",
    "#!pip install python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will actually need this\n",
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "C:\\Users\\peter\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "#from pyAudioAnalysis import audioBasicIO #don't really need pyaudioanalysis\n",
    "#from pyAudioAnalysis import ShortTermFeatures"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Fs, x] = audioBasicIO.read_audio_file('scottish.wav')\n",
    "F, f_names = ShortTermFeatures.feature_extraction(x, Fs, 0.050*Fs, 0.025*Fs)\n",
    "plt.subplot(2,1,1); plt.plot(F[0,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[0]) \n",
    "plt.subplot(2,1,2); plt.plot(F[1,:]); plt.xlabel('Frame no'); plt.ylabel(f_names[1]); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "covariance:\n",
    "\n",
    "6 combinations:\n",
    "X X\n",
    "X Y\n",
    "X Z\n",
    "Y Y\n",
    "Z Z\n",
    "Y Z"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#this doesn't really mean anything, just use the raw mfcc values\n",
    "i = 1120\n",
    "xx = numpy.cov(mfcc_x[i],mfcc_x[i])\n",
    "xy = numpy.cov(mfcc_x[i],mfcc_y[i])\n",
    "xz = numpy.cov(mfcc_x[i],mfcc_z[i])\n",
    "yy = numpy.cov(mfcc_y[i],mfcc_y[i])\n",
    "zz = numpy.cov(mfcc_z[i],mfcc_z[i])\n",
    "yz = numpy.cov(mfcc_y[i],mfcc_z[i])\n",
    "\n",
    "print(np.unique(np.array([xx,xy,xz,yy,zz,yz])))\n",
    "\n",
    "print(mfcc_x[i])\n",
    "print(mfcc_y[i])\n",
    "print(mfcc_z[i])\n",
    "\n",
    "[xx,xy,xz,yy,zz,yz]\n",
    "\n",
    "print(np.unique(np.arraynumpy.cov(mfcc_x[0],mfcc_y[0])))\n",
    "\n",
    "print(len(mfcc[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#true sampling rate is 40hz, but pyaudioanalysis wont take anything less than 10000\n",
    "Fsamp = 10000\n",
    "ShortTermFeatures.feature_extraction(np.array(dummy['x']), Fsamp, 0.050*Fsamp, 0.025*Fsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_pickle('joined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = original.pid.unique()\n",
    "\n",
    "dummy = original[original['pid'] == ids[0]]\n",
    "\n",
    "df = original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493739732016\n",
      "1493739733023\n",
      "1493739733043\n",
      "1493739734049\n",
      "1493739734070\n",
      "1493739735083\n",
      "1493739735103\n",
      "1493739736097\n"
     ]
    }
   ],
   "source": [
    "#51 rows ~ 1 second, where time is in milliseconds\n",
    "\n",
    "print(dummy['time'].iloc[0])\n",
    "print(dummy['time'].iloc[50])\n",
    "\n",
    "print(dummy['time'].iloc[51])\n",
    "print(dummy['time'].iloc[101])\n",
    "\n",
    "print(dummy['time'].iloc[102])\n",
    "print(dummy['time'].iloc[152])\n",
    "\n",
    "print(dummy['time'].iloc[153])\n",
    "print(dummy['time'].iloc[203])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZeroCrossingRate(arr):\n",
    "        my_array = np.array(arr)\n",
    "        return float(\"{0:.2f}\".format((((my_array[:-1] * my_array[1:]) < 0).sum())/len(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_and_zero_cross(df, pid):\n",
    "    \n",
    "    sec = 51\n",
    "    short = sec*2\n",
    "    full = sec*10\n",
    "    big = sec*1000\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy().reset_index().drop('index', axis = 1)\n",
    "    \n",
    "    windows = np.arange(0,len(df),big)\n",
    "    \n",
    "    \n",
    "    df['x_fft_1'] = 0\n",
    "    df['x_fft_2'] = 0\n",
    "    df['x_fft_3'] = 0\n",
    "\n",
    "    df['y_fft_1'] = 0\n",
    "    df['y_fft_2'] = 0\n",
    "    df['y_fft_3'] = 0\n",
    "    \n",
    "    df['z_fft_1'] = 0\n",
    "    df['z_fft_2'] = 0\n",
    "    df['z_fft_3'] = 0\n",
    "\n",
    "    df_app = pd.DataFrame(columns = df.columns)\n",
    "    \n",
    "    for i in range(len(windows)-1):\n",
    "        \n",
    "        small = df.iloc[windows[i]:windows[i+1]].copy()\n",
    "        \n",
    "        x_fft = scipy.fft.fft(np.array(small['x'])).real\n",
    "        \n",
    "        small['x_fft_1'] = x_fft[0]\n",
    "        small['x_fft_2'] = x_fft[1]\n",
    "        small['x_fft_3'] = x_fft[2]\n",
    "        small['x_fft_max'] = x_fft.max()\n",
    "        \n",
    "        small['x_zcr'] = getZeroCrossingRate(np.array(small['x']))\n",
    "        \n",
    "        y_fft = scipy.fft.fft(np.array(small['y'])).real\n",
    "        \n",
    "        small['y_fft_1'] = y_fft[0]\n",
    "        small['y_fft_2'] = y_fft[1]\n",
    "        small['y_fft_3'] = y_fft[2]\n",
    "        small['y_fft_max'] = y_fft.max()\n",
    "        \n",
    "        small['y_zcr'] = getZeroCrossingRate(np.array(small['y']))\n",
    "        \n",
    "        z_fft = scipy.fft.fft(np.array(small['z'])).real\n",
    "        \n",
    "        small['z_fft_1'] = z_fft[0]\n",
    "        small['z_fft_2'] = z_fft[1]\n",
    "        small['z_fft_3'] = z_fft[2]\n",
    "        small['z_fft_max'] = z_fft.max()\n",
    "        \n",
    "        small['z_zcr'] = getZeroCrossingRate(np.array(small['z']))\n",
    "        \n",
    "        df_app = df_app.append(small)\n",
    "        \n",
    "    df = df_app\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(df, pid):\n",
    "    \n",
    "    #give whole df, one pid at a time\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy().reset_index().drop('index', axis = 1)\n",
    "    \n",
    "    Fs = 40\n",
    "    mfcc_x_array = librosa.feature.mfcc(np.array(df['x']), sr=Fs).T\n",
    "    mfcc_y_array = librosa.feature.mfcc(np.array(df['y']), sr=Fs).T\n",
    "    mfcc_z_array = librosa.feature.mfcc(np.array(df['z']), sr=Fs).T\n",
    "\n",
    "    x_mfcc = pd.DataFrame(mfcc_x_array)\n",
    "    y_mfcc = pd.DataFrame(mfcc_y_array)\n",
    "    z_mfcc = pd.DataFrame(mfcc_z_array)\n",
    "\n",
    "    expansion_x = round(len(df)/len(x_mfcc))\n",
    "    new_index_x = (pd.DataFrame(x_mfcc).index * expansion_x)\n",
    "    x_mfcc.index = new_index_x\n",
    "\n",
    "    expansion_y = round(len(df)/len(y_mfcc))\n",
    "    new_index_y = (pd.DataFrame(y_mfcc).index * expansion_y)\n",
    "    y_mfcc.index = new_index_x\n",
    "\n",
    "    expansion_z = round(len(df)/len(z_mfcc))\n",
    "    new_index_z = (pd.DataFrame(z_mfcc).index * expansion_z)\n",
    "    z_mfcc.index = new_index_z\n",
    "\n",
    "    df = pd.merge_asof(df,x_mfcc, left_index = True, right_index = True)\n",
    "    df = pd.merge_asof(df,y_mfcc, left_index = True, right_index = True)\n",
    "    df = pd.merge_asof(df,z_mfcc, left_index = True, right_index = True)\n",
    " \n",
    "    #new_names = [(i,i+'_z') for i in df.iloc[:, 6:].columns.values]\n",
    "    #df.rename(columns = dict(new_names), inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(df,pid):\n",
    "    \n",
    "    #give whole df, one pid at a time\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy()\n",
    "    \n",
    "    sec = 51\n",
    "    short = sec*2\n",
    "    full = sec*10\n",
    "    \n",
    "    df['x_rms'] = ((df['x']**2)**.5).rolling(window=short).mean()\n",
    "    df['y_rms'] = ((df['y']**2)**.5).rolling(window=short).mean()\n",
    "    df['z_rms'] = ((df['z']**2)**.5).rolling(window=short).mean()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic(df,pid):\n",
    "     \n",
    "    sec = 51\n",
    "    short = sec*2\n",
    "    full = sec*10\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy()\n",
    "    \n",
    "    df['x_mean_short'] = df['x'].rolling(window=short).mean()\n",
    "    df['x_std_short'] = df['x'].rolling(window=short).std()\n",
    "    df['x_mean_long'] = df['x'].rolling(window=full).mean()\n",
    "    df['x_std_long'] = df['x'].rolling(window=full).std()\n",
    "    \n",
    "    df['y_mean_short'] = df['y'].rolling(window=short).mean()\n",
    "    df['y_std_short'] = df['y'].rolling(window=short).std()\n",
    "    df['y_mean_long'] = df['y'].rolling(window=full).mean()\n",
    "    df['y_std_long'] = df['y'].rolling(window=full).std()\n",
    "                          \n",
    "    df['z_mean_short'] = df['z'].rolling(window=short).mean()\n",
    "    df['z_std_short'] = df['z'].rolling(window=short).std()\n",
    "    df['z_mean_long'] = df['z'].rolling(window=full).mean()\n",
    "    df['z_std_long'] = df['z'].rolling(window=full).std()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(df,pid,feature):\n",
    "    \n",
    "    #give this x, y, z, for each pid\n",
    "    \n",
    "    sec = 51\n",
    "    short = sec*2\n",
    "    full = sec*10\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy()\n",
    "    \n",
    "    df[feature + '_mean'] = df[feature].rolling(window=full).mean()\n",
    "    df[feature + '_median'] = df[feature].rolling(window=full).median()\n",
    "    df[feature + '_std'] = df[feature].rolling(window=full).std()\n",
    "    \n",
    "    df = summarize(df,pid,feature + '_mean')\n",
    "    df = summarize(df,pid,feature + '_median')\n",
    "    df = summarize(df,pid,feature + '_std')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df,pid,feature):\n",
    "    \n",
    "    #called by extract, don't call separately\n",
    "    \n",
    "    #feature: mean over rolling window of 10 seconds\n",
    "    #break into windows of 2 seconds\n",
    "    #take mean, variance, max, min of those 5 windows as new features\n",
    "    #take mean of bottom 2 seconds and mean of top 2 seconds as new features\n",
    "    \n",
    "    df = df[df['pid'] == pid].copy()\n",
    "    \n",
    "    sec = 51\n",
    "    short = sec*2\n",
    "    full = sec*10\n",
    "    \n",
    "    df[feature + '_first'] = df[feature].shift(short*4).rolling(window=short).mean()\n",
    "    df['second'] = df[feature].shift(short*3).rolling(window=short).mean()\n",
    "    df['third'] = df[feature].shift(short*2).rolling(window=short).mean()\n",
    "    df['fourth'] = df[feature].shift(short*1).rolling(window=short).mean()\n",
    "    df[feature + '_fifth'] = df[feature].rolling(window=short).mean()\n",
    "    \n",
    "    df[feature + '_mean'] = df[[feature + '_first', 'second', \n",
    "                                'third', 'fourth', feature + '_fifth']].mean(axis=1)\n",
    "    \n",
    "    df[feature + '_var'] = df[[feature + '_first', 'second', \n",
    "                                'third', 'fourth', feature + '_fifth']].var(axis=1)\n",
    "    \n",
    "    df[feature + '_max'] = df[[feature + '_first', 'second', \n",
    "                                'third', 'fourth', feature + '_fifth']].max(axis=1)\n",
    "    \n",
    "    df[feature + '_min'] = df[[feature + '_first', 'second', \n",
    "                                'third', 'fourth', feature + '_fifth']].min(axis=1)\n",
    "    \n",
    "    df.drop(['second','third','fourth'],axis = 1, inplace = True)\n",
    "    \n",
    "    df[feature + '_first' + '_diff'] = df[feature + '_first'].diff(periods = full)\n",
    "    df[feature + '_fifth' + '_diff'] = df[feature + '_fifth'].diff(periods = full)\n",
    "    df[feature + '_mean' + '_diff'] = df[feature + '_mean'].diff(periods = full)\n",
    "    df[feature + '_var' + '_diff'] = df[feature + '_var'].diff(periods = full)\n",
    "    df[feature + '_max' + '_diff'] = df[feature + '_max'].diff(periods = full)\n",
    "    df[feature + '_min' + '_diff'] = df[feature + '_max'].diff(periods = full)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=77, microseconds=953226)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate 3 fft components and max, and zero crossing rate for each pid\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "fz_df = pd.DataFrame(columns = (fft_and_zero_cross(df, ids[0])).columns)\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    fz_df = fz_df.append(fft_and_zero_cross(df,ids[i]))\n",
    "    \n",
    "df = fz_df\n",
    "    \n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=86, microseconds=426366)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate mfccs for each pid\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "mfcc_df = pd.DataFrame(columns = (mfcc(df, ids[0])).columns)\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    mfcc_df = mfcc_df.append(mfcc(df,ids[i]))\n",
    "    \n",
    "df = mfcc_df\n",
    "    \n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=130, microseconds=70697)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate rms for x, y, and z for each pid\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "rms_df = pd.DataFrame(columns = (rms(df, ids[0])).columns)\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    rms_df = rms_df.append(rms(df,ids[i]))\n",
    "    \n",
    "df = rms_df\n",
    "    \n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=221, microseconds=434334)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate rolling mean and std for x, y, and z for each pid\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "basic_df = pd.DataFrame(columns = (basic(df, ids[0])).columns)\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    basic_df = basic_df.append(basic(df,ids[i]))\n",
    "    \n",
    "df = basic_df\n",
    "    \n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#could randomly sample 10% of this final step\n",
    "#this may give you a memory error.  it's really big.\n",
    "\n",
    "#perform 2 tier rolling window analysis on \n",
    "#mean, median, and std of x, y, and z for each pid\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "for ii in ['x','y','z']:\n",
    "\n",
    "    extract_df = pd.DataFrame(columns = (extract(df, ids[0], ii)).columns)\n",
    "\n",
    "    for i in range(len(ids)):\n",
    "        extract_df = extract_df.append(extract(df,ids[i], ii))\n",
    "\n",
    "    df = extract_df\n",
    "    \n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=74, microseconds=504682)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comes out to ~7 gigs\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "df.to_pickle('./processed.pkl')\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "end - start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
