{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../project_data/every_ten_seconds.pkl\")\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df['time'] = df['time'].astype(float)\n",
    "# we need to order by time to make splitting easier\n",
    "df.sort_values(by = ['time'], ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the cutoff point of 0.08 to distinguish between intoxicated and sober classes. It is the legal limit for intoxication while driving and according to the National Institute on Alcohol Abuse and Alcoholism it marks the onset of a binge drinking event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target\n",
    "df['TAC_Reading_binary'] = np.array([1 if tac >= 0.08 else 0 for tac in df['TAC_Reading'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 3-fold cross-validation to evaluate each model's performance. We implement this manually (rather on relying on scikit-learn's implementations), because our data is not i.i.d. Scikit-learn implementations usually shuffle the data or make it difficult to guarantee non-overlapping folds. In our case, shuffling the data leads to an inflated validation score, as the model will be tested on samples that are close in time (and hence artificially similar) to its training samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 26137 observations in the training data\n",
      "train_fold_1 will have 17425 observations\n",
      "train_fold_2 will have 17425 observations\n",
      "train_fold_3 will have 17424 observations\n",
      "test_fold_1 will have 8712 observations\n",
      "test_fold_2 will have 8712 observations\n",
      "test_fold_3 will have 8713 observations\n"
     ]
    }
   ],
   "source": [
    "# store indices for each split\n",
    "train_1_indices = np.arange(8712, len(df))\n",
    "test_1_indices = np.arange(0, 8712)\n",
    "train_2_indices = np.concatenate((np.arange(0, 8712), np.arange(8712*2, len(df))))\n",
    "test_2_indices = np.arange(8712, 8712*2)\n",
    "train_3_indices = np.arange(0, 8712*2)\n",
    "test_3_indices = np.arange(8712*2, len(df))\n",
    "\n",
    "# how many training observations in each fold?\n",
    "print('there are', len(df), 'observations in the training data')\n",
    "print('train_fold_1 will have', len(train_1_indices), 'observations')\n",
    "print('train_fold_2 will have', len(train_2_indices), 'observations')\n",
    "print('train_fold_3 will have', len(train_3_indices), 'observations')\n",
    "print('test_fold_1 will have', len(test_1_indices), 'observations')\n",
    "print('test_fold_2 will have', len(test_2_indices), 'observations')\n",
    "print('test_fold_3 will have', len(test_3_indices), 'observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_inputs(X_train, X_test):\n",
    "    '''\n",
    "    Standardize a train-test split using mean and standard deviation estimates from training data.\n",
    "    Returns a tuple of standardized training and test matrices.\n",
    "    '''\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(X_train)\n",
    "    X_train_scaled = scale.transform(X_train)\n",
    "    X_test_scaled = scale.transform(X_test)\n",
    "    return(X_train_scaled, X_test_scaled)\n",
    "\n",
    "def data_for_modeling(train_indices, test_indices, standardize = True, multi_input = False, multi_output = False, data = df):\n",
    "    '''\n",
    "    Get the training and test arrays for predictors and target to feed into your model.\n",
    "    Objects returned in a tuple in the following order: (X_train_objects, ..., X_test_objects, ..., y_train_objects, ..., y_test_objects)\n",
    "    Standardizes X appropriately, unless standardize = False, in which case X is not standardized.\n",
    "    If multi_input = True, multiple X objects are returned (to be used in wide and deep network).\n",
    "    If multi_output = True, multiple y objects are returned (to be used in multi-task network).\n",
    "    Does not support both multi_input and multi_output.\n",
    "    '''\n",
    "    # prepare target\n",
    "    y_train = df.iloc[train_indices]['TAC_Reading_binary'].values\n",
    "    y_test = df.iloc[test_indices]['TAC_Reading_binary'].values\n",
    "    if multi_output:\n",
    "        y_train_classification = df.iloc[train_indices]['TAC_Reading_binary'].values\n",
    "        y_train_regression = df.iloc[train_indices]['TAC_Reading'].values\n",
    "        y_test_classification = df.iloc[test_indices]['TAC_Reading_binary'].values\n",
    "        y_test_regression = df.iloc[test_indices]['TAC_Reading'].values\n",
    "    \n",
    "    # prepare predictors\n",
    "    X_train = df.iloc[train_indices].drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "    X_test = df.iloc[test_indices].drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "    if multi_input:\n",
    "        X_train_wide = X_train.drop(['x', 'y', 'z'], axis = 1)\n",
    "        X_test_wide = X_test.drop(['x', 'y', 'z'], axis = 1)    \n",
    "        X_train_deep = X_train.loc[:, ['x', 'y', 'z']]\n",
    "        X_test_deep = X_test.loc[:, ['x', 'y', 'z']]\n",
    "    \n",
    "    # standardization\n",
    "    if standardize:\n",
    "        if multi_input:\n",
    "            X_train_wide_scaled, X_test_wide_scaled = standardize_inputs(X_train_wide, X_test_wide)\n",
    "            X_train_deep_scaled, X_test_deep_scaled = standardize_inputs(X_train_deep, X_test_deep)\n",
    "        else:\n",
    "            X_train_scaled, X_test_scaled = standardize_inputs(X_train, X_test)\n",
    "\n",
    "    # returns\n",
    "    if multi_input:\n",
    "        if standardize:\n",
    "            return(X_train_wide_scaled, X_train_deep_scaled, X_test_wide_scaled, X_test_deep_scaled, y_train, y_test)\n",
    "        else:\n",
    "            return(X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test)\n",
    "    elif multi_output:\n",
    "        if standardize:\n",
    "            return(X_train_scaled, X_test_scaled, y_train_classification, y_train_regression, y_test_classification, y_test_regression)\n",
    "        else:\n",
    "            return(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression)\n",
    "    else:\n",
    "        if standardize:\n",
    "            return(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        else:\n",
    "            return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# containers to store results\n",
    "model = []\n",
    "fold = []\n",
    "accuracy = []\n",
    "precision_intox = []\n",
    "precision_sober = []\n",
    "recall_intox = []\n",
    "recall_sober = []\n",
    "support_sober = []\n",
    "support_intox = []\n",
    "\n",
    "results = {'model': model, 'fold': fold, 'accuracy' : accuracy, 'precision (intoxicated)': precision_intox,\n",
    "          'precision (sober)': precision_sober, 'recall (intoxicated)': recall_intox, 'recall (sober)': recall_sober, \n",
    "           'support (sober)': support_sober, 'support (intox)': support_intox}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Regular feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regular_feedforward(X_train, X_test, y_train, y_test, name):\n",
    "    '''\n",
    "    Creates regular feedforward NN and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify network architecture\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape = (99,)),\n",
    "        keras.layers.Dropout(rate = 0.3),\n",
    "        keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\"),\n",
    "        keras.layers.Dropout(rate = 0.3),\n",
    "        keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\"),\n",
    "        keras.layers.Dropout(rate = 0.3),\n",
    "        keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\"),\n",
    "        keras.layers.Dropout(rate = 0.3),\n",
    "        keras.layers.Dense(units = 1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    # compilation\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    # exponential learning rate scheduler\n",
    "    def exponential_decay(lr0, s):\n",
    "        def exponential_decay_fn(epoch):\n",
    "            return lr0 * 0.1**(epoch / s)\n",
    "        return exponential_decay_fn\n",
    "\n",
    "    exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "    lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'regular_feedforward_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size = 32, epochs = 50, validation_data = (X_test, y_test),\n",
    "                        callbacks = [checkpoint_cb, lr_scheduler, early_stopping_cb], verbose = 2)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 19s - loss: 0.3436 - accuracy: 0.8636 - val_loss: 1.3535 - val_accuracy: 0.5527\n",
      "Epoch 2/50\n",
      "17425/17425 - 20s - loss: 0.2661 - accuracy: 0.8826 - val_loss: 1.3310 - val_accuracy: 0.5733\n",
      "Epoch 3/50\n",
      "17425/17425 - 16s - loss: 0.2524 - accuracy: 0.8886 - val_loss: 1.2886 - val_accuracy: 0.5896\n",
      "Epoch 4/50\n",
      "17425/17425 - 15s - loss: 0.2358 - accuracy: 0.8898 - val_loss: 1.1185 - val_accuracy: 0.5658\n",
      "Epoch 5/50\n",
      "17425/17425 - 15s - loss: 0.2299 - accuracy: 0.8921 - val_loss: 1.3756 - val_accuracy: 0.5853\n",
      "Epoch 6/50\n",
      "17425/17425 - 15s - loss: 0.2214 - accuracy: 0.8976 - val_loss: 1.2982 - val_accuracy: 0.5880\n",
      "Epoch 7/50\n",
      "17425/17425 - 16s - loss: 0.2154 - accuracy: 0.8971 - val_loss: 1.3047 - val_accuracy: 0.5924\n",
      "Epoch 8/50\n",
      "17425/17425 - 17s - loss: 0.2098 - accuracy: 0.9021 - val_loss: 1.2574 - val_accuracy: 0.5900\n",
      "Epoch 9/50\n",
      "17425/17425 - 16s - loss: 0.1996 - accuracy: 0.9081 - val_loss: 1.1974 - val_accuracy: 0.5562\n",
      "Epoch 10/50\n",
      "17425/17425 - 15s - loss: 0.1971 - accuracy: 0.9082 - val_loss: 1.3081 - val_accuracy: 0.5940\n",
      "Epoch 11/50\n",
      "17425/17425 - 14s - loss: 0.1957 - accuracy: 0.9090 - val_loss: 1.2471 - val_accuracy: 0.5917\n",
      "Epoch 12/50\n",
      "17425/17425 - 14s - loss: 0.1882 - accuracy: 0.9121 - val_loss: 1.2488 - val_accuracy: 0.5841\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.1834 - accuracy: 0.9152 - val_loss: 1.3502 - val_accuracy: 0.5792\n",
      "Epoch 14/50\n",
      "17425/17425 - 13s - loss: 0.1829 - accuracy: 0.9126 - val_loss: 1.2078 - val_accuracy: 0.5981\n",
      "Epoch 15/50\n",
      "17425/17425 - 13s - loss: 0.1824 - accuracy: 0.9131 - val_loss: 1.3362 - val_accuracy: 0.5925\n",
      "Epoch 16/50\n",
      "17425/17425 - 13s - loss: 0.1842 - accuracy: 0.9127 - val_loss: 1.2457 - val_accuracy: 0.5933\n",
      "Epoch 17/50\n",
      "17425/17425 - 13s - loss: 0.1823 - accuracy: 0.9147 - val_loss: 1.2587 - val_accuracy: 0.5961\n",
      "Epoch 18/50\n",
      "17425/17425 - 13s - loss: 0.1805 - accuracy: 0.9148 - val_loss: 1.2575 - val_accuracy: 0.5933\n",
      "Epoch 19/50\n",
      "17425/17425 - 13s - loss: 0.1824 - accuracy: 0.9136 - val_loss: 1.1739 - val_accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices)\n",
    "# fit model\n",
    "feedforward_1 = train_regular_feedforward(X_train, X_test, y_train, y_test, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = feedforward_1.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record results\n",
    "model += ['regular feedforward']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 18s - loss: 0.5497 - accuracy: 0.7541 - val_loss: 0.4490 - val_accuracy: 0.7743\n",
      "Epoch 2/50\n",
      "17425/17425 - 15s - loss: 0.4811 - accuracy: 0.7685 - val_loss: 0.5688 - val_accuracy: 0.7272\n",
      "Epoch 3/50\n",
      "17425/17425 - 15s - loss: 0.4524 - accuracy: 0.7733 - val_loss: 0.5375 - val_accuracy: 0.7126\n",
      "Epoch 4/50\n",
      "17425/17425 - 15s - loss: 0.4331 - accuracy: 0.7756 - val_loss: 0.5250 - val_accuracy: 0.7487\n",
      "Epoch 5/50\n",
      "17425/17425 - 14s - loss: 0.4194 - accuracy: 0.7840 - val_loss: 0.4979 - val_accuracy: 0.7542\n",
      "Epoch 6/50\n",
      "17425/17425 - 14s - loss: 0.4095 - accuracy: 0.7872 - val_loss: 0.4909 - val_accuracy: 0.7495\n",
      "Epoch 7/50\n",
      "17425/17425 - 14s - loss: 0.4026 - accuracy: 0.7904 - val_loss: 0.4895 - val_accuracy: 0.7603\n",
      "Epoch 8/50\n",
      "17425/17425 - 15s - loss: 0.3900 - accuracy: 0.7956 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 9/50\n",
      "17425/17425 - 15s - loss: 0.3853 - accuracy: 0.8000 - val_loss: 0.4803 - val_accuracy: 0.7444\n",
      "Epoch 10/50\n",
      "17425/17425 - 14s - loss: 0.3811 - accuracy: 0.8005 - val_loss: 0.4888 - val_accuracy: 0.7554\n",
      "Epoch 11/50\n",
      "17425/17425 - 16s - loss: 0.3781 - accuracy: 0.8018 - val_loss: 0.4981 - val_accuracy: 0.7306\n",
      "Epoch 12/50\n",
      "17425/17425 - 14s - loss: 0.3749 - accuracy: 0.7987 - val_loss: 0.4682 - val_accuracy: 0.7471\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.3643 - accuracy: 0.8078 - val_loss: 0.4806 - val_accuracy: 0.7557\n",
      "Epoch 14/50\n",
      "17425/17425 - 14s - loss: 0.3616 - accuracy: 0.8121 - val_loss: 0.4708 - val_accuracy: 0.7552\n",
      "Epoch 15/50\n",
      "17425/17425 - 14s - loss: 0.3623 - accuracy: 0.8093 - val_loss: 0.4561 - val_accuracy: 0.7596\n",
      "Epoch 16/50\n",
      "17425/17425 - 14s - loss: 0.3562 - accuracy: 0.8112 - val_loss: 0.4784 - val_accuracy: 0.7575\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices)\n",
    "# fit model\n",
    "feedforward_2 = train_regular_feedforward(X_train, X_test, y_train, y_test, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = feedforward_2.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['regular feedforward']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17424 samples, validate on 8713 samples\n",
      "Epoch 1/50\n",
      "17424/17424 - 16s - loss: 0.7384 - accuracy: 0.6477 - val_loss: 0.1357 - val_accuracy: 0.9392\n",
      "Epoch 2/50\n",
      "17424/17424 - 14s - loss: 0.6767 - accuracy: 0.6666 - val_loss: 0.2138 - val_accuracy: 0.9380\n",
      "Epoch 3/50\n",
      "17424/17424 - 14s - loss: 0.6440 - accuracy: 0.6742 - val_loss: 0.1303 - val_accuracy: 0.9564\n",
      "Epoch 4/50\n",
      "17424/17424 - 14s - loss: 0.6103 - accuracy: 0.6861 - val_loss: 0.1447 - val_accuracy: 0.9210\n",
      "Epoch 5/50\n",
      "17424/17424 - 14s - loss: 0.5858 - accuracy: 0.6930 - val_loss: 0.1172 - val_accuracy: 0.9518\n",
      "Epoch 6/50\n",
      "17424/17424 - 14s - loss: 0.5724 - accuracy: 0.6985 - val_loss: 0.1243 - val_accuracy: 0.9492\n",
      "Epoch 7/50\n",
      "17424/17424 - 14s - loss: 0.5604 - accuracy: 0.7056 - val_loss: 0.1426 - val_accuracy: 0.9635\n",
      "Epoch 8/50\n",
      "17424/17424 - 14s - loss: 0.5493 - accuracy: 0.7084 - val_loss: 0.1520 - val_accuracy: 0.9249\n",
      "Epoch 9/50\n",
      "17424/17424 - 13s - loss: 0.5381 - accuracy: 0.7125 - val_loss: 0.1489 - val_accuracy: 0.9543\n",
      "Epoch 10/50\n",
      "17424/17424 - 13s - loss: 0.5300 - accuracy: 0.7203 - val_loss: 0.1531 - val_accuracy: 0.9278\n",
      "Epoch 11/50\n",
      "17424/17424 - 13s - loss: 0.5261 - accuracy: 0.7173 - val_loss: 0.1253 - val_accuracy: 0.9415\n",
      "Epoch 12/50\n",
      "17424/17424 - 14s - loss: 0.5204 - accuracy: 0.7258 - val_loss: 0.1282 - val_accuracy: 0.9391\n",
      "Epoch 13/50\n",
      "17424/17424 - 13s - loss: 0.5124 - accuracy: 0.7311 - val_loss: 0.1741 - val_accuracy: 0.9156\n",
      "Epoch 14/50\n",
      "17424/17424 - 13s - loss: 0.5092 - accuracy: 0.7301 - val_loss: 0.1305 - val_accuracy: 0.9498\n",
      "Epoch 15/50\n",
      "17424/17424 - 13s - loss: 0.5053 - accuracy: 0.7335 - val_loss: 0.1545 - val_accuracy: 0.9089\n",
      "Epoch 16/50\n",
      "17424/17424 - 13s - loss: 0.4991 - accuracy: 0.7397 - val_loss: 0.1341 - val_accuracy: 0.9428\n",
      "Epoch 17/50\n",
      "17424/17424 - 13s - loss: 0.4968 - accuracy: 0.7364 - val_loss: 0.1598 - val_accuracy: 0.9148\n",
      "Epoch 18/50\n",
      "17424/17424 - 14s - loss: 0.4975 - accuracy: 0.7345 - val_loss: 0.1416 - val_accuracy: 0.9376\n",
      "Epoch 19/50\n",
      "17424/17424 - 14s - loss: 0.4908 - accuracy: 0.7433 - val_loss: 0.1577 - val_accuracy: 0.9236\n",
      "Epoch 20/50\n",
      "17424/17424 - 15s - loss: 0.4880 - accuracy: 0.7439 - val_loss: 0.1404 - val_accuracy: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yannik/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices)\n",
    "# fit model\n",
    "feedforward_3 = train_regular_feedforward(X_train, X_test, y_train, y_test, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = feedforward_3.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['regular feedforward']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Wide and deep feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wide_deep_feedforward(X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test, name):\n",
    "    '''\n",
    "    Creates wide and deep feedforward NN and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify network architecture\n",
    "    wide_input = keras.layers.Input(shape = (96,), name = 'wide_input')\n",
    "    deep_input = keras.layers.Input(shape = (3,), name = 'deep_input')\n",
    "    hidden_1 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(deep_input)\n",
    "    dropout_1 = keras.layers.Dropout(rate = 0.3)(hidden_1)\n",
    "    hidden_2 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(dropout_1)\n",
    "    dropout_2 = keras.layers.Dropout(rate = 0.3)(hidden_2)\n",
    "    hidden_3 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(dropout_2)\n",
    "    dropout_3 = keras.layers.Dropout(rate = 0.3)(hidden_3)\n",
    "    dropout_wide = keras.layers.Dropout(rate = 0.3)(wide_input)\n",
    "    concat = keras.layers.concatenate([dropout_wide, dropout_3])\n",
    "    output = keras.layers.Dense(units = 1, activation = \"sigmoid\")(concat)\n",
    "    model = keras.Model(inputs = [wide_input, deep_input], outputs = [output])\n",
    "    \n",
    "    # compilation\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'wide_deep_feedforward_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    model.fit((X_train_wide, X_train_deep), y_train, batch_size = 32, epochs = 50, validation_data = ((X_test_wide, X_test_deep), y_test),\n",
    "                        callbacks = [checkpoint_cb, lr_scheduler, early_stopping_cb], verbose = 2)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 17s - loss: 0.3825 - accuracy: 0.8735 - val_loss: 1.3326 - val_accuracy: 0.5680\n",
      "Epoch 2/50\n",
      "17425/17425 - 13s - loss: 0.3383 - accuracy: 0.8799 - val_loss: 1.3561 - val_accuracy: 0.5514\n",
      "Epoch 3/50\n",
      "17425/17425 - 15s - loss: 0.3159 - accuracy: 0.8813 - val_loss: 1.2525 - val_accuracy: 0.5698\n",
      "Epoch 4/50\n",
      "17425/17425 - 14s - loss: 0.2876 - accuracy: 0.8853 - val_loss: 1.1039 - val_accuracy: 0.5899\n",
      "Epoch 5/50\n",
      "17425/17425 - 14s - loss: 0.2826 - accuracy: 0.8859 - val_loss: 1.1146 - val_accuracy: 0.5875\n",
      "Epoch 6/50\n",
      "17425/17425 - 14s - loss: 0.2847 - accuracy: 0.8856 - val_loss: 1.1267 - val_accuracy: 0.5764\n",
      "Epoch 7/50\n",
      "17425/17425 - 15s - loss: 0.2792 - accuracy: 0.8872 - val_loss: 1.1151 - val_accuracy: 0.5658\n",
      "Epoch 8/50\n",
      "17425/17425 - 14s - loss: 0.2773 - accuracy: 0.8830 - val_loss: 1.0767 - val_accuracy: 0.5830\n",
      "Epoch 9/50\n",
      "17425/17425 - 14s - loss: 0.2794 - accuracy: 0.8865 - val_loss: 1.0530 - val_accuracy: 0.5927\n",
      "Epoch 10/50\n",
      "17425/17425 - 15s - loss: 0.2788 - accuracy: 0.8851 - val_loss: 1.1099 - val_accuracy: 0.5816\n",
      "Epoch 11/50\n",
      "17425/17425 - 14s - loss: 0.2809 - accuracy: 0.8852 - val_loss: 1.0724 - val_accuracy: 0.5731\n",
      "Epoch 12/50\n",
      "17425/17425 - 14s - loss: 0.2702 - accuracy: 0.8866 - val_loss: 1.0695 - val_accuracy: 0.5678\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.2787 - accuracy: 0.8844 - val_loss: 1.0197 - val_accuracy: 0.5783\n",
      "Epoch 14/50\n",
      "17425/17425 - 14s - loss: 0.2742 - accuracy: 0.8860 - val_loss: 1.0507 - val_accuracy: 0.5753\n",
      "Epoch 15/50\n",
      "17425/17425 - 13s - loss: 0.2700 - accuracy: 0.8879 - val_loss: 1.1502 - val_accuracy: 0.5735\n",
      "Epoch 16/50\n",
      "17425/17425 - 14s - loss: 0.2690 - accuracy: 0.8871 - val_loss: 1.0654 - val_accuracy: 0.5751\n",
      "Epoch 17/50\n",
      "17425/17425 - 14s - loss: 0.2771 - accuracy: 0.8856 - val_loss: 1.0973 - val_accuracy: 0.5817\n",
      "Epoch 18/50\n",
      "17425/17425 - 13s - loss: 0.2764 - accuracy: 0.8870 - val_loss: 1.1239 - val_accuracy: 0.5895\n",
      "Epoch 19/50\n",
      "17425/17425 - 14s - loss: 0.2527 - accuracy: 0.8911 - val_loss: 1.0461 - val_accuracy: 0.5792\n",
      "Epoch 20/50\n",
      "17425/17425 - 13s - loss: 0.2461 - accuracy: 0.8919 - val_loss: 0.9999 - val_accuracy: 0.5946\n",
      "Epoch 21/50\n",
      "17425/17425 - 15s - loss: 0.2438 - accuracy: 0.8919 - val_loss: 1.0245 - val_accuracy: 0.5867\n",
      "Epoch 22/50\n",
      "17425/17425 - 21s - loss: 0.2441 - accuracy: 0.8910 - val_loss: 1.0335 - val_accuracy: 0.5890\n",
      "Epoch 23/50\n",
      "17425/17425 - 16s - loss: 0.2458 - accuracy: 0.8914 - val_loss: 1.0367 - val_accuracy: 0.5914\n",
      "Epoch 24/50\n",
      "17425/17425 - 15s - loss: 0.2468 - accuracy: 0.8906 - val_loss: 1.0153 - val_accuracy: 0.5745\n",
      "Epoch 25/50\n",
      "17425/17425 - 15s - loss: 0.2459 - accuracy: 0.8910 - val_loss: 1.0332 - val_accuracy: 0.5821\n",
      "Epoch 26/50\n",
      "17425/17425 - 17s - loss: 0.2359 - accuracy: 0.8936 - val_loss: 1.0067 - val_accuracy: 0.5871\n",
      "Epoch 27/50\n",
      "17425/17425 - 21s - loss: 0.2335 - accuracy: 0.8939 - val_loss: 1.0227 - val_accuracy: 0.5861\n",
      "Epoch 28/50\n",
      "17425/17425 - 16s - loss: 0.2340 - accuracy: 0.8942 - val_loss: 1.0195 - val_accuracy: 0.5868\n",
      "Epoch 29/50\n",
      "17425/17425 - 15s - loss: 0.2331 - accuracy: 0.8927 - val_loss: 1.0080 - val_accuracy: 0.5798\n",
      "Epoch 30/50\n",
      "17425/17425 - 19s - loss: 0.2347 - accuracy: 0.8934 - val_loss: 0.9886 - val_accuracy: 0.5894\n",
      "Epoch 31/50\n",
      "17425/17425 - 15s - loss: 0.2323 - accuracy: 0.8927 - val_loss: 1.0020 - val_accuracy: 0.5853\n",
      "Epoch 32/50\n",
      "17425/17425 - 15s - loss: 0.2329 - accuracy: 0.8918 - val_loss: 1.0033 - val_accuracy: 0.5813\n",
      "Epoch 33/50\n",
      "17425/17425 - 14s - loss: 0.2350 - accuracy: 0.8925 - val_loss: 0.9844 - val_accuracy: 0.5841\n",
      "Epoch 34/50\n",
      "17425/17425 - 14s - loss: 0.2333 - accuracy: 0.8925 - val_loss: 0.9892 - val_accuracy: 0.5901\n",
      "Epoch 35/50\n",
      "17425/17425 - 14s - loss: 0.2317 - accuracy: 0.8961 - val_loss: 0.9777 - val_accuracy: 0.5886\n",
      "Epoch 36/50\n",
      "17425/17425 - 13s - loss: 0.2376 - accuracy: 0.8921 - val_loss: 0.9980 - val_accuracy: 0.5808\n",
      "Epoch 37/50\n",
      "17425/17425 - 13s - loss: 0.2319 - accuracy: 0.8965 - val_loss: 0.9988 - val_accuracy: 0.5815\n",
      "Epoch 38/50\n",
      "17425/17425 - 13s - loss: 0.2307 - accuracy: 0.8928 - val_loss: 0.9839 - val_accuracy: 0.5957\n",
      "Epoch 39/50\n",
      "17425/17425 - 13s - loss: 0.2314 - accuracy: 0.8963 - val_loss: 0.9947 - val_accuracy: 0.5893\n",
      "Epoch 40/50\n",
      "17425/17425 - 13s - loss: 0.2346 - accuracy: 0.8919 - val_loss: 0.9905 - val_accuracy: 0.5869\n",
      "Epoch 41/50\n",
      "17425/17425 - 13s - loss: 0.2256 - accuracy: 0.8960 - val_loss: 0.9967 - val_accuracy: 0.5860\n",
      "Epoch 42/50\n",
      "17425/17425 - 13s - loss: 0.2317 - accuracy: 0.8926 - val_loss: 0.9758 - val_accuracy: 0.5818\n",
      "Epoch 43/50\n",
      "17425/17425 - 13s - loss: 0.2284 - accuracy: 0.8953 - val_loss: 0.9940 - val_accuracy: 0.5776\n",
      "Epoch 44/50\n",
      "17425/17425 - 13s - loss: 0.2293 - accuracy: 0.8937 - val_loss: 0.9889 - val_accuracy: 0.5798\n",
      "Epoch 45/50\n",
      "17425/17425 - 13s - loss: 0.2257 - accuracy: 0.8958 - val_loss: 0.9776 - val_accuracy: 0.5914\n",
      "Epoch 46/50\n",
      "17425/17425 - 13s - loss: 0.2325 - accuracy: 0.8920 - val_loss: 0.9844 - val_accuracy: 0.5852\n",
      "Epoch 47/50\n",
      "17425/17425 - 13s - loss: 0.2301 - accuracy: 0.8952 - val_loss: 0.9817 - val_accuracy: 0.5822\n",
      "Epoch 48/50\n",
      "17425/17425 - 13s - loss: 0.2253 - accuracy: 0.8956 - val_loss: 0.9681 - val_accuracy: 0.5860\n",
      "Epoch 49/50\n",
      "17425/17425 - 15s - loss: 0.2255 - accuracy: 0.8968 - val_loss: 0.9793 - val_accuracy: 0.5832\n",
      "Epoch 50/50\n",
      "17425/17425 - 14s - loss: 0.2282 - accuracy: 0.8927 - val_loss: 0.9837 - val_accuracy: 0.5802\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, multi_input = True)\n",
    "# fit model\n",
    "wide_deep_1 = train_wide_deep_feedforward(X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = wide_deep_1.predict((X_test_wide, X_test_deep))\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['wide and deep feedforward']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 19s - loss: 0.5239 - accuracy: 0.7757 - val_loss: 0.6090 - val_accuracy: 0.7290\n",
      "Epoch 2/50\n",
      "17425/17425 - 14s - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.5582 - val_accuracy: 0.7452\n",
      "Epoch 3/50\n",
      "17425/17425 - 14s - loss: 0.4644 - accuracy: 0.7815 - val_loss: 0.6072 - val_accuracy: 0.7243\n",
      "Epoch 4/50\n",
      "17425/17425 - 14s - loss: 0.4683 - accuracy: 0.7774 - val_loss: 0.5963 - val_accuracy: 0.7207\n",
      "Epoch 5/50\n",
      "17425/17425 - 14s - loss: 0.4598 - accuracy: 0.7804 - val_loss: 0.5405 - val_accuracy: 0.7239\n",
      "Epoch 6/50\n",
      "17425/17425 - 14s - loss: 0.4476 - accuracy: 0.7798 - val_loss: 0.5150 - val_accuracy: 0.7332\n",
      "Epoch 7/50\n",
      "17425/17425 - 16s - loss: 0.4492 - accuracy: 0.7806 - val_loss: 0.5272 - val_accuracy: 0.7327\n",
      "Epoch 8/50\n",
      "17425/17425 - 14s - loss: 0.4492 - accuracy: 0.7818 - val_loss: 0.5446 - val_accuracy: 0.7338\n",
      "Epoch 9/50\n",
      "17425/17425 - 15s - loss: 0.4443 - accuracy: 0.7814 - val_loss: 0.5150 - val_accuracy: 0.7415\n",
      "Epoch 10/50\n",
      "17425/17425 - 14s - loss: 0.4455 - accuracy: 0.7799 - val_loss: 0.5412 - val_accuracy: 0.7345\n",
      "Epoch 11/50\n",
      "17425/17425 - 14s - loss: 0.4498 - accuracy: 0.7803 - val_loss: 0.5747 - val_accuracy: 0.7146\n",
      "Epoch 12/50\n",
      "17425/17425 - 14s - loss: 0.4238 - accuracy: 0.7851 - val_loss: 0.4895 - val_accuracy: 0.7345\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.4155 - accuracy: 0.7859 - val_loss: 0.5204 - val_accuracy: 0.7247\n",
      "Epoch 14/50\n",
      "17425/17425 - 13s - loss: 0.4166 - accuracy: 0.7876 - val_loss: 0.4907 - val_accuracy: 0.7317\n",
      "Epoch 15/50\n",
      "17425/17425 - 13s - loss: 0.4150 - accuracy: 0.7886 - val_loss: 0.4846 - val_accuracy: 0.7237\n",
      "Epoch 16/50\n",
      "17425/17425 - 14s - loss: 0.4153 - accuracy: 0.7891 - val_loss: 0.4850 - val_accuracy: 0.7369\n",
      "Epoch 17/50\n",
      "17425/17425 - 13s - loss: 0.4155 - accuracy: 0.7878 - val_loss: 0.4972 - val_accuracy: 0.7317\n",
      "Epoch 18/50\n",
      "17425/17425 - 14s - loss: 0.4133 - accuracy: 0.7869 - val_loss: 0.4932 - val_accuracy: 0.7260\n",
      "Epoch 19/50\n",
      "17425/17425 - 14s - loss: 0.4125 - accuracy: 0.7877 - val_loss: 0.5140 - val_accuracy: 0.7187\n",
      "Epoch 20/50\n",
      "17425/17425 - 13s - loss: 0.4130 - accuracy: 0.7878 - val_loss: 0.5096 - val_accuracy: 0.7245\n",
      "Epoch 21/50\n",
      "17425/17425 - 13s - loss: 0.4065 - accuracy: 0.7881 - val_loss: 0.4735 - val_accuracy: 0.7391\n",
      "Epoch 22/50\n",
      "17425/17425 - 18s - loss: 0.4035 - accuracy: 0.7901 - val_loss: 0.4862 - val_accuracy: 0.7307\n",
      "Epoch 23/50\n",
      "17425/17425 - 17s - loss: 0.4002 - accuracy: 0.7897 - val_loss: 0.5001 - val_accuracy: 0.7289\n",
      "Epoch 24/50\n",
      "17425/17425 - 15s - loss: 0.4046 - accuracy: 0.7898 - val_loss: 0.4752 - val_accuracy: 0.7422\n",
      "Epoch 25/50\n",
      "17425/17425 - 16s - loss: 0.4029 - accuracy: 0.7861 - val_loss: 0.4811 - val_accuracy: 0.7324\n",
      "Epoch 26/50\n",
      "17425/17425 - 16s - loss: 0.4013 - accuracy: 0.7937 - val_loss: 0.4991 - val_accuracy: 0.7299\n",
      "Epoch 27/50\n",
      "17425/17425 - 17s - loss: 0.4002 - accuracy: 0.7904 - val_loss: 0.4741 - val_accuracy: 0.7330\n",
      "Epoch 28/50\n",
      "17425/17425 - 14s - loss: 0.3978 - accuracy: 0.7881 - val_loss: 0.4898 - val_accuracy: 0.7221\n",
      "Epoch 29/50\n",
      "17425/17425 - 15s - loss: 0.3970 - accuracy: 0.7943 - val_loss: 0.4747 - val_accuracy: 0.7355\n",
      "Epoch 30/50\n",
      "17425/17425 - 20s - loss: 0.3988 - accuracy: 0.7914 - val_loss: 0.4759 - val_accuracy: 0.7353\n",
      "Epoch 31/50\n",
      "17425/17425 - 15s - loss: 0.3969 - accuracy: 0.7971 - val_loss: 0.4882 - val_accuracy: 0.7266\n",
      "Epoch 32/50\n",
      "17425/17425 - 13s - loss: 0.3958 - accuracy: 0.7933 - val_loss: 0.4785 - val_accuracy: 0.7289\n",
      "Epoch 33/50\n",
      "17425/17425 - 13s - loss: 0.3950 - accuracy: 0.7942 - val_loss: 0.4837 - val_accuracy: 0.7253\n",
      "Epoch 34/50\n",
      "17425/17425 - 13s - loss: 0.3946 - accuracy: 0.7917 - val_loss: 0.4825 - val_accuracy: 0.7280\n",
      "Epoch 35/50\n",
      "17425/17425 - 14s - loss: 0.3943 - accuracy: 0.7936 - val_loss: 0.4804 - val_accuracy: 0.7261\n",
      "Epoch 36/50\n",
      "17425/17425 - 13s - loss: 0.3966 - accuracy: 0.7899 - val_loss: 0.4794 - val_accuracy: 0.7289\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, multi_input = True)\n",
    "# fit model\n",
    "wide_deep_2 = train_wide_deep_feedforward(X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = wide_deep_2.predict((X_test_wide, X_test_deep))\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['wide and deep feedforward']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17424 samples, validate on 8713 samples\n",
      "Epoch 1/50\n",
      "17424/17424 - 16s - loss: 0.7029 - accuracy: 0.6709 - val_loss: 0.2942 - val_accuracy: 0.9387\n",
      "Epoch 2/50\n",
      "17424/17424 - 13s - loss: 0.6333 - accuracy: 0.6820 - val_loss: 0.2751 - val_accuracy: 0.9475\n",
      "Epoch 3/50\n",
      "17424/17424 - 14s - loss: 0.6208 - accuracy: 0.6769 - val_loss: 0.1826 - val_accuracy: 0.9558\n",
      "Epoch 4/50\n",
      "17424/17424 - 16s - loss: 0.6096 - accuracy: 0.6841 - val_loss: 0.1915 - val_accuracy: 0.9661\n",
      "Epoch 5/50\n",
      "17424/17424 - 14s - loss: 0.6080 - accuracy: 0.6841 - val_loss: 0.2098 - val_accuracy: 0.9604\n",
      "Epoch 6/50\n",
      "17424/17424 - 15s - loss: 0.6073 - accuracy: 0.6810 - val_loss: 0.2625 - val_accuracy: 0.9539\n",
      "Epoch 7/50\n",
      "17424/17424 - 14s - loss: 0.5996 - accuracy: 0.6838 - val_loss: 0.1790 - val_accuracy: 0.9571\n",
      "Epoch 8/50\n",
      "17424/17424 - 13s - loss: 0.6022 - accuracy: 0.6861 - val_loss: 0.1928 - val_accuracy: 0.9570\n",
      "Epoch 9/50\n",
      "17424/17424 - 13s - loss: 0.6091 - accuracy: 0.6835 - val_loss: 0.1924 - val_accuracy: 0.9601\n",
      "Epoch 10/50\n",
      "17424/17424 - 17s - loss: 0.6043 - accuracy: 0.6820 - val_loss: 0.1861 - val_accuracy: 0.9435\n",
      "Epoch 11/50\n",
      "17424/17424 - 17s - loss: 0.6068 - accuracy: 0.6839 - val_loss: 0.2684 - val_accuracy: 0.9345\n",
      "Epoch 12/50\n",
      "17424/17424 - 16s - loss: 0.6043 - accuracy: 0.6806 - val_loss: 0.2240 - val_accuracy: 0.9448\n",
      "Epoch 13/50\n",
      "17424/17424 - 16s - loss: 0.5769 - accuracy: 0.6942 - val_loss: 0.1723 - val_accuracy: 0.9696\n",
      "Epoch 14/50\n",
      "17424/17424 - 15s - loss: 0.5714 - accuracy: 0.6893 - val_loss: 0.1757 - val_accuracy: 0.9574\n",
      "Epoch 15/50\n",
      "17424/17424 - 16s - loss: 0.5721 - accuracy: 0.6903 - val_loss: 0.1811 - val_accuracy: 0.9590\n",
      "Epoch 16/50\n",
      "17424/17424 - 14s - loss: 0.5703 - accuracy: 0.6917 - val_loss: 0.1630 - val_accuracy: 0.9541\n",
      "Epoch 17/50\n",
      "17424/17424 - 16s - loss: 0.5698 - accuracy: 0.6925 - val_loss: 0.1897 - val_accuracy: 0.9583\n",
      "Epoch 18/50\n",
      "17424/17424 - 15s - loss: 0.5718 - accuracy: 0.6881 - val_loss: 0.1902 - val_accuracy: 0.9641\n",
      "Epoch 19/50\n",
      "17424/17424 - 15s - loss: 0.5688 - accuracy: 0.6895 - val_loss: 0.1791 - val_accuracy: 0.9714\n",
      "Epoch 20/50\n",
      "17424/17424 - 14s - loss: 0.5664 - accuracy: 0.6911 - val_loss: 0.1971 - val_accuracy: 0.9643\n",
      "Epoch 21/50\n",
      "17424/17424 - 15s - loss: 0.5688 - accuracy: 0.6890 - val_loss: 0.1973 - val_accuracy: 0.9555\n",
      "Epoch 22/50\n",
      "17424/17424 - 15s - loss: 0.5604 - accuracy: 0.6971 - val_loss: 0.2066 - val_accuracy: 0.9591\n",
      "Epoch 23/50\n",
      "17424/17424 - 17s - loss: 0.5583 - accuracy: 0.6979 - val_loss: 0.1840 - val_accuracy: 0.9655\n",
      "Epoch 24/50\n",
      "17424/17424 - 14s - loss: 0.5579 - accuracy: 0.6935 - val_loss: 0.2055 - val_accuracy: 0.9632\n",
      "Epoch 25/50\n",
      "17424/17424 - 15s - loss: 0.5582 - accuracy: 0.6969 - val_loss: 0.2066 - val_accuracy: 0.9618\n",
      "Epoch 26/50\n",
      "17424/17424 - 16s - loss: 0.5566 - accuracy: 0.7001 - val_loss: 0.1911 - val_accuracy: 0.9555\n",
      "Epoch 27/50\n",
      "17424/17424 - 14s - loss: 0.5506 - accuracy: 0.7016 - val_loss: 0.1964 - val_accuracy: 0.9557\n",
      "Epoch 28/50\n",
      "17424/17424 - 14s - loss: 0.5510 - accuracy: 0.6977 - val_loss: 0.1861 - val_accuracy: 0.9593\n",
      "Epoch 29/50\n",
      "17424/17424 - 15s - loss: 0.5524 - accuracy: 0.6985 - val_loss: 0.1885 - val_accuracy: 0.9585\n",
      "Epoch 30/50\n",
      "17424/17424 - 16s - loss: 0.5526 - accuracy: 0.6982 - val_loss: 0.1984 - val_accuracy: 0.9651\n",
      "Epoch 31/50\n",
      "17424/17424 - 16s - loss: 0.5482 - accuracy: 0.7038 - val_loss: 0.2134 - val_accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, multi_input = True)\n",
    "# fit model\n",
    "wide_deep_3 = train_wide_deep_feedforward(X_train_wide, X_train_deep, X_test_wide, X_test_deep, y_train, y_test, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = wide_deep_3.predict((X_test_wide, X_test_deep))\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['wide and deep feedforward']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Multi-task feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi_task_feedforward(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression, name):\n",
    "    '''\n",
    "    Creates multi-task feedforward NN and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    The two tasks are classification of TAC and regression of TAC.\n",
    "    '''\n",
    "    # specify network architecture\n",
    "    input_layer = keras.layers.Input(shape = (99,), name = 'input_layer')\n",
    "    hidden_1 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(input_layer)\n",
    "    dropout_1 = keras.layers.Dropout(rate = 0.3)(hidden_1)\n",
    "    hidden_2 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(dropout_1)\n",
    "    dropout_2 = keras.layers.Dropout(rate = 0.3)(hidden_2)\n",
    "    hidden_3 = keras.layers.Dense(units = 300, activation = \"selu\", kernel_initializer = \"lecun_normal\")(dropout_2)\n",
    "    dropout_3 = keras.layers.Dropout(rate = 0.3)(hidden_3)\n",
    "    classifier_output = keras.layers.Dense(units = 1, activation = \"sigmoid\", name = 'classifier')(dropout_3)\n",
    "    regression_output = keras.layers.Dense(units = 1, activation = \"sigmoid\", name = 'regressor')(dropout_3)\n",
    "    model = keras.Model(inputs = [input_layer], outputs = [classifier_output, regression_output])\n",
    "    \n",
    "    # compilation\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = ['binary_crossentropy', 'mean_squared_error'], optimizer = optimizer, \n",
    "                  metrics = [['accuracy'], ['mse']])\n",
    "    \n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'multi_task_feedforward_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    model.fit(X_train, [y_train_classification, y_train_regression], batch_size = 32, epochs = 50, \n",
    "              validation_data = (X_test, [y_test_classification, y_test_regression]), \n",
    "              callbacks = [lr_scheduler, early_stopping_cb, checkpoint_cb], verbose = 2)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 20s - loss: 0.3227 - classifier_loss: 0.3076 - regressor_loss: 0.0150 - classifier_accuracy: 0.8767 - regressor_mse: 0.0150 - val_loss: 1.7067 - val_classifier_loss: 1.6972 - val_regressor_loss: 0.0075 - val_classifier_accuracy: 0.5865 - val_regressor_mse: 0.0075\n",
      "Epoch 2/50\n",
      "17425/17425 - 16s - loss: 0.2491 - classifier_loss: 0.2447 - regressor_loss: 0.0043 - classifier_accuracy: 0.8969 - regressor_mse: 0.0043 - val_loss: 1.4237 - val_classifier_loss: 1.4152 - val_regressor_loss: 0.0073 - val_classifier_accuracy: 0.5948 - val_regressor_mse: 0.0073\n",
      "Epoch 3/50\n",
      "17425/17425 - 15s - loss: 0.2207 - classifier_loss: 0.2168 - regressor_loss: 0.0038 - classifier_accuracy: 0.9072 - regressor_mse: 0.0038 - val_loss: 1.5511 - val_classifier_loss: 1.5430 - val_regressor_loss: 0.0076 - val_classifier_accuracy: 0.5704 - val_regressor_mse: 0.0076\n",
      "Epoch 4/50\n",
      "17425/17425 - 15s - loss: 0.2087 - classifier_loss: 0.2050 - regressor_loss: 0.0038 - classifier_accuracy: 0.9139 - regressor_mse: 0.0038 - val_loss: 1.6077 - val_classifier_loss: 1.5983 - val_regressor_loss: 0.0068 - val_classifier_accuracy: 0.5841 - val_regressor_mse: 0.0068\n",
      "Epoch 5/50\n",
      "17425/17425 - 16s - loss: 0.1980 - classifier_loss: 0.1944 - regressor_loss: 0.0035 - classifier_accuracy: 0.9175 - regressor_mse: 0.0035 - val_loss: 1.6359 - val_classifier_loss: 1.6275 - val_regressor_loss: 0.0066 - val_classifier_accuracy: 0.5848 - val_regressor_mse: 0.0066\n",
      "Epoch 6/50\n",
      "17425/17425 - 16s - loss: 0.1932 - classifier_loss: 0.1897 - regressor_loss: 0.0033 - classifier_accuracy: 0.9184 - regressor_mse: 0.0033 - val_loss: 1.6528 - val_classifier_loss: 1.6453 - val_regressor_loss: 0.0065 - val_classifier_accuracy: 0.5701 - val_regressor_mse: 0.0065\n",
      "Epoch 7/50\n",
      "17425/17425 - 15s - loss: 0.1821 - classifier_loss: 0.1787 - regressor_loss: 0.0033 - classifier_accuracy: 0.9231 - regressor_mse: 0.0033 - val_loss: 2.0185 - val_classifier_loss: 2.0101 - val_regressor_loss: 0.0062 - val_classifier_accuracy: 0.5987 - val_regressor_mse: 0.0062\n",
      "Epoch 8/50\n",
      "17425/17425 - 18s - loss: 0.1556 - classifier_loss: 0.1526 - regressor_loss: 0.0030 - classifier_accuracy: 0.9318 - regressor_mse: 0.0030 - val_loss: 1.8839 - val_classifier_loss: 1.8750 - val_regressor_loss: 0.0058 - val_classifier_accuracy: 0.5926 - val_regressor_mse: 0.0058\n",
      "Epoch 9/50\n",
      "17425/17425 - 16s - loss: 0.1475 - classifier_loss: 0.1450 - regressor_loss: 0.0028 - classifier_accuracy: 0.9356 - regressor_mse: 0.0028 - val_loss: 1.8707 - val_classifier_loss: 1.8613 - val_regressor_loss: 0.0059 - val_classifier_accuracy: 0.5929 - val_regressor_mse: 0.0059\n",
      "Epoch 10/50\n",
      "17425/17425 - 14s - loss: 0.1422 - classifier_loss: 0.1394 - regressor_loss: 0.0029 - classifier_accuracy: 0.9402 - regressor_mse: 0.0029 - val_loss: 1.8844 - val_classifier_loss: 1.8758 - val_regressor_loss: 0.0055 - val_classifier_accuracy: 0.6049 - val_regressor_mse: 0.0055\n",
      "Epoch 11/50\n",
      "17425/17425 - 14s - loss: 0.1360 - classifier_loss: 0.1333 - regressor_loss: 0.0028 - classifier_accuracy: 0.9431 - regressor_mse: 0.0028 - val_loss: 1.7548 - val_classifier_loss: 1.7464 - val_regressor_loss: 0.0055 - val_classifier_accuracy: 0.5857 - val_regressor_mse: 0.0055\n",
      "Epoch 12/50\n",
      "17425/17425 - 14s - loss: 0.1296 - classifier_loss: 0.1270 - regressor_loss: 0.0026 - classifier_accuracy: 0.9459 - regressor_mse: 0.0026 - val_loss: 1.9675 - val_classifier_loss: 1.9586 - val_regressor_loss: 0.0052 - val_classifier_accuracy: 0.5907 - val_regressor_mse: 0.0052\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.1257 - classifier_loss: 0.1233 - regressor_loss: 0.0025 - classifier_accuracy: 0.9478 - regressor_mse: 0.0025 - val_loss: 1.8603 - val_classifier_loss: 1.8518 - val_regressor_loss: 0.0053 - val_classifier_accuracy: 0.5940 - val_regressor_mse: 0.0053\n",
      "Epoch 14/50\n",
      "17425/17425 - 14s - loss: 0.1181 - classifier_loss: 0.1156 - regressor_loss: 0.0024 - classifier_accuracy: 0.9512 - regressor_mse: 0.0024 - val_loss: 1.8152 - val_classifier_loss: 1.8070 - val_regressor_loss: 0.0051 - val_classifier_accuracy: 0.5963 - val_regressor_mse: 0.0051\n",
      "Epoch 15/50\n",
      "17425/17425 - 14s - loss: 0.1180 - classifier_loss: 0.1156 - regressor_loss: 0.0024 - classifier_accuracy: 0.9488 - regressor_mse: 0.0024 - val_loss: 2.0290 - val_classifier_loss: 2.0203 - val_regressor_loss: 0.0049 - val_classifier_accuracy: 0.5991 - val_regressor_mse: 0.0049\n",
      "Epoch 16/50\n",
      "17425/17425 - 14s - loss: 0.1147 - classifier_loss: 0.1125 - regressor_loss: 0.0023 - classifier_accuracy: 0.9515 - regressor_mse: 0.0023 - val_loss: 1.9104 - val_classifier_loss: 1.9024 - val_regressor_loss: 0.0047 - val_classifier_accuracy: 0.5946 - val_regressor_mse: 0.0047\n",
      "Epoch 17/50\n",
      "17425/17425 - 14s - loss: 0.1147 - classifier_loss: 0.1125 - regressor_loss: 0.0022 - classifier_accuracy: 0.9507 - regressor_mse: 0.0022 - val_loss: 2.0928 - val_classifier_loss: 2.0839 - val_regressor_loss: 0.0048 - val_classifier_accuracy: 0.5940 - val_regressor_mse: 0.0048\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression = data_for_modeling(train_1_indices, test_1_indices, multi_output = True)\n",
    "# fit model\n",
    "multi_task_1 = train_multi_task_feedforward(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression, 'fold_1')\n",
    "# get predictions\n",
    "pred_prob, _ = multi_task_1.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['multi-task feedforward']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test_classification, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17425 samples, validate on 8712 samples\n",
      "Epoch 1/50\n",
      "17425/17425 - 18s - loss: 0.5186 - classifier_loss: 0.5015 - regressor_loss: 0.0170 - classifier_accuracy: 0.7696 - regressor_mse: 0.0170 - val_loss: 0.5953 - val_classifier_loss: 0.5877 - val_regressor_loss: 0.0061 - val_classifier_accuracy: 0.7127 - val_regressor_mse: 0.0061\n",
      "Epoch 2/50\n",
      "17425/17425 - 15s - loss: 0.4556 - classifier_loss: 0.4505 - regressor_loss: 0.0053 - classifier_accuracy: 0.7857 - regressor_mse: 0.0053 - val_loss: 0.5460 - val_classifier_loss: 0.5384 - val_regressor_loss: 0.0062 - val_classifier_accuracy: 0.7423 - val_regressor_mse: 0.0062\n",
      "Epoch 3/50\n",
      "17425/17425 - 14s - loss: 0.4365 - classifier_loss: 0.4318 - regressor_loss: 0.0048 - classifier_accuracy: 0.7942 - regressor_mse: 0.0048 - val_loss: 0.5614 - val_classifier_loss: 0.5539 - val_regressor_loss: 0.0059 - val_classifier_accuracy: 0.7599 - val_regressor_mse: 0.0059\n",
      "Epoch 4/50\n",
      "17425/17425 - 14s - loss: 0.4252 - classifier_loss: 0.4206 - regressor_loss: 0.0045 - classifier_accuracy: 0.7989 - regressor_mse: 0.0045 - val_loss: 0.6522 - val_classifier_loss: 0.6445 - val_regressor_loss: 0.0060 - val_classifier_accuracy: 0.7090 - val_regressor_mse: 0.0060\n",
      "Epoch 5/50\n",
      "17425/17425 - 14s - loss: 0.4178 - classifier_loss: 0.4135 - regressor_loss: 0.0043 - classifier_accuracy: 0.8044 - regressor_mse: 0.0043 - val_loss: 0.5956 - val_classifier_loss: 0.5883 - val_regressor_loss: 0.0058 - val_classifier_accuracy: 0.7220 - val_regressor_mse: 0.0058\n",
      "Epoch 6/50\n",
      "17425/17425 - 13s - loss: 0.4027 - classifier_loss: 0.3987 - regressor_loss: 0.0040 - classifier_accuracy: 0.8117 - regressor_mse: 0.0040 - val_loss: 0.6078 - val_classifier_loss: 0.6016 - val_regressor_loss: 0.0050 - val_classifier_accuracy: 0.7208 - val_regressor_mse: 0.0050\n",
      "Epoch 7/50\n",
      "17425/17425 - 13s - loss: 0.4002 - classifier_loss: 0.3960 - regressor_loss: 0.0040 - classifier_accuracy: 0.8135 - regressor_mse: 0.0040 - val_loss: 0.6610 - val_classifier_loss: 0.6542 - val_regressor_loss: 0.0052 - val_classifier_accuracy: 0.7171 - val_regressor_mse: 0.0052\n",
      "Epoch 8/50\n",
      "17425/17425 - 13s - loss: 0.3512 - classifier_loss: 0.3478 - regressor_loss: 0.0035 - classifier_accuracy: 0.8262 - regressor_mse: 0.0035 - val_loss: 0.5352 - val_classifier_loss: 0.5287 - val_regressor_loss: 0.0050 - val_classifier_accuracy: 0.7477 - val_regressor_mse: 0.0051\n",
      "Epoch 9/50\n",
      "17425/17425 - 14s - loss: 0.3409 - classifier_loss: 0.3376 - regressor_loss: 0.0033 - classifier_accuracy: 0.8311 - regressor_mse: 0.0033 - val_loss: 0.5838 - val_classifier_loss: 0.5772 - val_regressor_loss: 0.0051 - val_classifier_accuracy: 0.7427 - val_regressor_mse: 0.0051\n",
      "Epoch 10/50\n",
      "17425/17425 - 14s - loss: 0.3298 - classifier_loss: 0.3269 - regressor_loss: 0.0031 - classifier_accuracy: 0.8399 - regressor_mse: 0.0031 - val_loss: 0.5635 - val_classifier_loss: 0.5572 - val_regressor_loss: 0.0048 - val_classifier_accuracy: 0.7451 - val_regressor_mse: 0.0048\n",
      "Epoch 11/50\n",
      "17425/17425 - 13s - loss: 0.3252 - classifier_loss: 0.3220 - regressor_loss: 0.0030 - classifier_accuracy: 0.8375 - regressor_mse: 0.0030 - val_loss: 0.5728 - val_classifier_loss: 0.5669 - val_regressor_loss: 0.0044 - val_classifier_accuracy: 0.7480 - val_regressor_mse: 0.0044\n",
      "Epoch 12/50\n",
      "17425/17425 - 13s - loss: 0.3271 - classifier_loss: 0.3245 - regressor_loss: 0.0028 - classifier_accuracy: 0.8402 - regressor_mse: 0.0028 - val_loss: 0.5609 - val_classifier_loss: 0.5550 - val_regressor_loss: 0.0043 - val_classifier_accuracy: 0.7342 - val_regressor_mse: 0.0043\n",
      "Epoch 13/50\n",
      "17425/17425 - 14s - loss: 0.3194 - classifier_loss: 0.3166 - regressor_loss: 0.0027 - classifier_accuracy: 0.8442 - regressor_mse: 0.0027 - val_loss: 0.5801 - val_classifier_loss: 0.5746 - val_regressor_loss: 0.0039 - val_classifier_accuracy: 0.7476 - val_regressor_mse: 0.0039\n",
      "Epoch 14/50\n",
      "17425/17425 - 14s - loss: 0.3009 - classifier_loss: 0.2982 - regressor_loss: 0.0025 - classifier_accuracy: 0.8534 - regressor_mse: 0.0025 - val_loss: 0.5991 - val_classifier_loss: 0.5935 - val_regressor_loss: 0.0040 - val_classifier_accuracy: 0.7420 - val_regressor_mse: 0.0040\n",
      "Epoch 15/50\n",
      "17425/17425 - 13s - loss: 0.2957 - classifier_loss: 0.2932 - regressor_loss: 0.0026 - classifier_accuracy: 0.8545 - regressor_mse: 0.0026 - val_loss: 0.5776 - val_classifier_loss: 0.5724 - val_regressor_loss: 0.0037 - val_classifier_accuracy: 0.7482 - val_regressor_mse: 0.0037\n",
      "Epoch 16/50\n",
      "17425/17425 - 14s - loss: 0.2908 - classifier_loss: 0.2884 - regressor_loss: 0.0024 - classifier_accuracy: 0.8580 - regressor_mse: 0.0024 - val_loss: 0.5979 - val_classifier_loss: 0.5927 - val_regressor_loss: 0.0036 - val_classifier_accuracy: 0.7397 - val_regressor_mse: 0.0036\n",
      "Epoch 17/50\n",
      "17425/17425 - 14s - loss: 0.2862 - classifier_loss: 0.2838 - regressor_loss: 0.0024 - classifier_accuracy: 0.8612 - regressor_mse: 0.0024 - val_loss: 0.6003 - val_classifier_loss: 0.5950 - val_regressor_loss: 0.0037 - val_classifier_accuracy: 0.7323 - val_regressor_mse: 0.0037\n",
      "Epoch 18/50\n",
      "17425/17425 - 14s - loss: 0.2897 - classifier_loss: 0.2875 - regressor_loss: 0.0024 - classifier_accuracy: 0.8616 - regressor_mse: 0.0024 - val_loss: 0.5886 - val_classifier_loss: 0.5834 - val_regressor_loss: 0.0037 - val_classifier_accuracy: 0.7470 - val_regressor_mse: 0.0037\n",
      "Epoch 19/50\n",
      "17425/17425 - 14s - loss: 0.2805 - classifier_loss: 0.2783 - regressor_loss: 0.0024 - classifier_accuracy: 0.8639 - regressor_mse: 0.0024 - val_loss: 0.5602 - val_classifier_loss: 0.5550 - val_regressor_loss: 0.0037 - val_classifier_accuracy: 0.7454 - val_regressor_mse: 0.0037\n",
      "Epoch 20/50\n",
      "17425/17425 - 13s - loss: 0.2761 - classifier_loss: 0.2738 - regressor_loss: 0.0023 - classifier_accuracy: 0.8650 - regressor_mse: 0.0023 - val_loss: 0.5822 - val_classifier_loss: 0.5772 - val_regressor_loss: 0.0035 - val_classifier_accuracy: 0.7383 - val_regressor_mse: 0.0035\n",
      "Epoch 21/50\n",
      "17425/17425 - 14s - loss: 0.2724 - classifier_loss: 0.2700 - regressor_loss: 0.0023 - classifier_accuracy: 0.8689 - regressor_mse: 0.0023 - val_loss: 0.5663 - val_classifier_loss: 0.5611 - val_regressor_loss: 0.0037 - val_classifier_accuracy: 0.7445 - val_regressor_mse: 0.0037\n",
      "Epoch 22/50\n",
      "17425/17425 - 13s - loss: 0.2735 - classifier_loss: 0.2713 - regressor_loss: 0.0022 - classifier_accuracy: 0.8659 - regressor_mse: 0.0022 - val_loss: 0.5674 - val_classifier_loss: 0.5625 - val_regressor_loss: 0.0035 - val_classifier_accuracy: 0.7490 - val_regressor_mse: 0.0035\n",
      "Epoch 23/50\n",
      "17425/17425 - 14s - loss: 0.2733 - classifier_loss: 0.2713 - regressor_loss: 0.0022 - classifier_accuracy: 0.8658 - regressor_mse: 0.0022 - val_loss: 0.5828 - val_classifier_loss: 0.5777 - val_regressor_loss: 0.0036 - val_classifier_accuracy: 0.7371 - val_regressor_mse: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression = data_for_modeling(train_2_indices, test_2_indices, multi_output = True)\n",
    "# fit model\n",
    "multi_task_2 = train_multi_task_feedforward(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression, 'fold_2')\n",
    "# get predictions\n",
    "pred_prob, _ = multi_task_2.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['multi-task feedforward']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test_classification, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17424 samples, validate on 8713 samples\n",
      "Epoch 1/50\n",
      "17424/17424 - 17s - loss: 0.7052 - classifier_loss: 0.6869 - regressor_loss: 0.0189 - classifier_accuracy: 0.6733 - regressor_mse: 0.0189 - val_loss: 0.1390 - val_classifier_loss: 0.1407 - val_regressor_loss: 4.1545e-04 - val_classifier_accuracy: 0.9401 - val_regressor_mse: 4.1220e-04\n",
      "Epoch 2/50\n",
      "17424/17424 - 14s - loss: 0.6444 - classifier_loss: 0.6366 - regressor_loss: 0.0078 - classifier_accuracy: 0.6917 - regressor_mse: 0.0078 - val_loss: 0.2659 - val_classifier_loss: 0.2687 - val_regressor_loss: 5.4181e-04 - val_classifier_accuracy: 0.8989 - val_regressor_mse: 5.4079e-04\n",
      "Epoch 3/50\n",
      "17424/17424 - 14s - loss: 0.6268 - classifier_loss: 0.6200 - regressor_loss: 0.0068 - classifier_accuracy: 0.7058 - regressor_mse: 0.0068 - val_loss: 0.1573 - val_classifier_loss: 0.1615 - val_regressor_loss: 7.7563e-04 - val_classifier_accuracy: 0.9374 - val_regressor_mse: 7.6273e-04\n",
      "Epoch 4/50\n",
      "17424/17424 - 14s - loss: 0.5976 - classifier_loss: 0.5916 - regressor_loss: 0.0058 - classifier_accuracy: 0.7153 - regressor_mse: 0.0058 - val_loss: 0.0984 - val_classifier_loss: 0.1029 - val_regressor_loss: 4.5503e-04 - val_classifier_accuracy: 0.9581 - val_regressor_mse: 4.5359e-04\n",
      "Epoch 5/50\n",
      "17424/17424 - 14s - loss: 0.5821 - classifier_loss: 0.5777 - regressor_loss: 0.0045 - classifier_accuracy: 0.7196 - regressor_mse: 0.0045 - val_loss: 0.1953 - val_classifier_loss: 0.1985 - val_regressor_loss: 0.0011 - val_classifier_accuracy: 0.9169 - val_regressor_mse: 0.0010\n",
      "Epoch 6/50\n",
      "17424/17424 - 14s - loss: 0.5699 - classifier_loss: 0.5663 - regressor_loss: 0.0038 - classifier_accuracy: 0.7318 - regressor_mse: 0.0038 - val_loss: 0.1831 - val_classifier_loss: 0.1869 - val_regressor_loss: 0.0011 - val_classifier_accuracy: 0.9169 - val_regressor_mse: 0.0011\n",
      "Epoch 7/50\n",
      "17424/17424 - 14s - loss: 0.5549 - classifier_loss: 0.5517 - regressor_loss: 0.0031 - classifier_accuracy: 0.7383 - regressor_mse: 0.0031 - val_loss: 0.1587 - val_classifier_loss: 0.1641 - val_regressor_loss: 0.0015 - val_classifier_accuracy: 0.9244 - val_regressor_mse: 0.0015\n",
      "Epoch 8/50\n",
      "17424/17424 - 14s - loss: 0.5523 - classifier_loss: 0.5496 - regressor_loss: 0.0028 - classifier_accuracy: 0.7398 - regressor_mse: 0.0028 - val_loss: 0.1482 - val_classifier_loss: 0.1490 - val_regressor_loss: 0.0018 - val_classifier_accuracy: 0.9377 - val_regressor_mse: 0.0018\n",
      "Epoch 9/50\n",
      "17424/17424 - 14s - loss: 0.5445 - classifier_loss: 0.5418 - regressor_loss: 0.0026 - classifier_accuracy: 0.7441 - regressor_mse: 0.0026 - val_loss: 0.1456 - val_classifier_loss: 0.1486 - val_regressor_loss: 0.0016 - val_classifier_accuracy: 0.9389 - val_regressor_mse: 0.0016\n",
      "Epoch 10/50\n",
      "17424/17424 - 14s - loss: 0.4727 - classifier_loss: 0.4703 - regressor_loss: 0.0023 - classifier_accuracy: 0.7714 - regressor_mse: 0.0023 - val_loss: 0.1520 - val_classifier_loss: 0.1551 - val_regressor_loss: 0.0017 - val_classifier_accuracy: 0.9335 - val_regressor_mse: 0.0017\n",
      "Epoch 11/50\n",
      "17424/17424 - 14s - loss: 0.4589 - classifier_loss: 0.4567 - regressor_loss: 0.0022 - classifier_accuracy: 0.7747 - regressor_mse: 0.0022 - val_loss: 0.1519 - val_classifier_loss: 0.1555 - val_regressor_loss: 0.0018 - val_classifier_accuracy: 0.9277 - val_regressor_mse: 0.0018\n",
      "Epoch 12/50\n",
      "17424/17424 - 14s - loss: 0.4508 - classifier_loss: 0.4486 - regressor_loss: 0.0021 - classifier_accuracy: 0.7785 - regressor_mse: 0.0021 - val_loss: 0.3139 - val_classifier_loss: 0.3181 - val_regressor_loss: 0.0019 - val_classifier_accuracy: 0.8547 - val_regressor_mse: 0.0018\n",
      "Epoch 13/50\n",
      "17424/17424 - 14s - loss: 0.4473 - classifier_loss: 0.4451 - regressor_loss: 0.0021 - classifier_accuracy: 0.7787 - regressor_mse: 0.0021 - val_loss: 0.1152 - val_classifier_loss: 0.1185 - val_regressor_loss: 0.0017 - val_classifier_accuracy: 0.9624 - val_regressor_mse: 0.0016\n",
      "Epoch 14/50\n",
      "17424/17424 - 14s - loss: 0.4412 - classifier_loss: 0.4391 - regressor_loss: 0.0021 - classifier_accuracy: 0.7852 - regressor_mse: 0.0021 - val_loss: 0.1688 - val_classifier_loss: 0.1724 - val_regressor_loss: 0.0017 - val_classifier_accuracy: 0.9238 - val_regressor_mse: 0.0017\n",
      "Epoch 15/50\n",
      "17424/17424 - 14s - loss: 0.4151 - classifier_loss: 0.4133 - regressor_loss: 0.0020 - classifier_accuracy: 0.7970 - regressor_mse: 0.0020 - val_loss: 0.1434 - val_classifier_loss: 0.1476 - val_regressor_loss: 0.0015 - val_classifier_accuracy: 0.9360 - val_regressor_mse: 0.0015\n",
      "Epoch 16/50\n",
      "17424/17424 - 15s - loss: 0.4085 - classifier_loss: 0.4067 - regressor_loss: 0.0020 - classifier_accuracy: 0.8006 - regressor_mse: 0.0020 - val_loss: 0.1294 - val_classifier_loss: 0.1326 - val_regressor_loss: 0.0018 - val_classifier_accuracy: 0.9475 - val_regressor_mse: 0.0017\n",
      "Epoch 17/50\n",
      "17424/17424 - 15s - loss: 0.4051 - classifier_loss: 0.4030 - regressor_loss: 0.0020 - classifier_accuracy: 0.8027 - regressor_mse: 0.0020 - val_loss: 0.1613 - val_classifier_loss: 0.1644 - val_regressor_loss: 0.0016 - val_classifier_accuracy: 0.9246 - val_regressor_mse: 0.0016\n",
      "Epoch 18/50\n",
      "17424/17424 - 15s - loss: 0.4001 - classifier_loss: 0.3980 - regressor_loss: 0.0020 - classifier_accuracy: 0.8050 - regressor_mse: 0.0020 - val_loss: 0.1381 - val_classifier_loss: 0.1418 - val_regressor_loss: 0.0016 - val_classifier_accuracy: 0.9434 - val_regressor_mse: 0.0016\n",
      "Epoch 19/50\n",
      "17424/17424 - 14s - loss: 0.3977 - classifier_loss: 0.3957 - regressor_loss: 0.0019 - classifier_accuracy: 0.8097 - regressor_mse: 0.0019 - val_loss: 0.1224 - val_classifier_loss: 0.1248 - val_regressor_loss: 0.0017 - val_classifier_accuracy: 0.9461 - val_regressor_mse: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression = data_for_modeling(train_3_indices, test_3_indices, multi_output = True)\n",
    "# fit model\n",
    "multi_task_3 = train_multi_task_feedforward(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression, 'fold_3')\n",
    "# get predictions\n",
    "pred_prob, _ = multi_task_3.predict(X_test)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "# record results\n",
    "model += ['multi-task feedforward']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test_classification, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test_classification, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision (intoxicated)</th>\n",
       "      <th>precision (sober)</th>\n",
       "      <th>recall (intoxicated)</th>\n",
       "      <th>recall (sober)</th>\n",
       "      <th>support (sober)</th>\n",
       "      <th>support (intox)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regular feedforward</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565771</td>\n",
       "      <td>0.540795</td>\n",
       "      <td>0.575482</td>\n",
       "      <td>0.331241</td>\n",
       "      <td>0.763214</td>\n",
       "      <td>4730</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regular feedforward</td>\n",
       "      <td>2</td>\n",
       "      <td>0.774334</td>\n",
       "      <td>0.584813</td>\n",
       "      <td>0.857049</td>\n",
       "      <td>0.640994</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>6297</td>\n",
       "      <td>2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regular feedforward</td>\n",
       "      <td>3</td>\n",
       "      <td>0.951796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951796</td>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wide and deep feedforward</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580234</td>\n",
       "      <td>0.564974</td>\n",
       "      <td>0.586379</td>\n",
       "      <td>0.354847</td>\n",
       "      <td>0.769979</td>\n",
       "      <td>4730</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wide and deep feedforward</td>\n",
       "      <td>2</td>\n",
       "      <td>0.739096</td>\n",
       "      <td>0.546834</td>\n",
       "      <td>0.779600</td>\n",
       "      <td>0.343271</td>\n",
       "      <td>0.890900</td>\n",
       "      <td>6297</td>\n",
       "      <td>2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wide and deep feedforward</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954092</td>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>multi-task feedforward</td>\n",
       "      <td>1</td>\n",
       "      <td>0.594812</td>\n",
       "      <td>0.577610</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.422401</td>\n",
       "      <td>0.739958</td>\n",
       "      <td>4730</td>\n",
       "      <td>3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multi-task feedforward</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747704</td>\n",
       "      <td>0.541114</td>\n",
       "      <td>0.837477</td>\n",
       "      <td>0.591304</td>\n",
       "      <td>0.807686</td>\n",
       "      <td>6297</td>\n",
       "      <td>2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>multi-task feedforward</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958109</td>\n",
       "      <td>8713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  fold  accuracy  precision (intoxicated)  \\\n",
       "0        regular feedforward     1  0.565771                 0.540795   \n",
       "1        regular feedforward     2  0.774334                 0.584813   \n",
       "2        regular feedforward     3  0.951796                 0.000000   \n",
       "3  wide and deep feedforward     1  0.580234                 0.564974   \n",
       "4  wide and deep feedforward     2  0.739096                 0.546834   \n",
       "5  wide and deep feedforward     3  0.954092                 0.000000   \n",
       "6     multi-task feedforward     1  0.594812                 0.577610   \n",
       "7     multi-task feedforward     2  0.747704                 0.541114   \n",
       "8     multi-task feedforward     3  0.958109                 0.000000   \n",
       "\n",
       "   precision (sober)  recall (intoxicated)  recall (sober)  support (sober)  \\\n",
       "0           0.575482              0.331241        0.763214             4730   \n",
       "1           0.857049              0.640994        0.825472             6297   \n",
       "2           1.000000              1.000000        0.951796             8713   \n",
       "3           0.586379              0.354847        0.769979             4730   \n",
       "4           0.779600              0.343271        0.890900             6297   \n",
       "5           1.000000              1.000000        0.954092             8713   \n",
       "6           0.603448              0.422401        0.739958             4730   \n",
       "7           0.837477              0.591304        0.807686             6297   \n",
       "8           1.000000              1.000000        0.958109             8713   \n",
       "\n",
       "   support (intox)  \n",
       "0             3982  \n",
       "1             2415  \n",
       "2                0  \n",
       "3             3982  \n",
       "4             2415  \n",
       "5                0  \n",
       "6             3982  \n",
       "7             2415  \n",
       "8                0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision (intoxicated)</th>\n",
       "      <th>precision (sober)</th>\n",
       "      <th>recall (intoxicated)</th>\n",
       "      <th>recall (sober)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi-task feedforward</td>\n",
       "      <td>0.766875</td>\n",
       "      <td>0.372908</td>\n",
       "      <td>0.813642</td>\n",
       "      <td>0.671235</td>\n",
       "      <td>0.835251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regular feedforward</td>\n",
       "      <td>0.763967</td>\n",
       "      <td>0.375203</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>0.657411</td>\n",
       "      <td>0.846827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wide and deep feedforward</td>\n",
       "      <td>0.757807</td>\n",
       "      <td>0.370603</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.566039</td>\n",
       "      <td>0.871657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  accuracy  precision (intoxicated)  \\\n",
       "0     multi-task feedforward  0.766875                 0.372908   \n",
       "1        regular feedforward  0.763967                 0.375203   \n",
       "2  wide and deep feedforward  0.757807                 0.370603   \n",
       "\n",
       "   precision (sober)  recall (intoxicated)  recall (sober)  \n",
       "0           0.813642              0.671235        0.835251  \n",
       "1           0.810844              0.657411        0.846827  \n",
       "2           0.788660              0.566039        0.871657  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).groupby('model', as_index = False).agg(np.mean).drop(['fold', 'support (sober)', 'support (intox)'], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
