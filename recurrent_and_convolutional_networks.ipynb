{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../project_data/every_half_second.pkl\")\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df['time'] = df['time'].astype(float)\n",
    "# we need to order by time to make splitting easier\n",
    "df.sort_values(by = ['time'], ignore_index = True, inplace = True)\n",
    "# prepare target\n",
    "df['TAC_Reading_binary'] = np.array([1 if tac >= 0.08 else 0 for tac in df['TAC_Reading'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our sequence networks, we'll be using a slightly different version of the data. Instead of every row corresponding to a sample taken every ten seconds, now every row corresponds to a sample taken every half second. Our problem frame is still: given a ten-second window of accelerometer data, can we accurately classify the person as sober or intoxicated. The only difference now is that our networks will take as input a sequence of 20 rows, sampled every half-second in time. And just as before we'll be using 3-fold cross-validation, implemented manually, to evaluate our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 533265 observations in the training data\n",
      "train_fold_1 will have 355510 observations\n",
      "train_fold_2 will have 355510 observations\n",
      "train_fold_3 will have 355510 observations\n",
      "test_fold_1 will have 177755 observations\n",
      "test_fold_2 will have 177755 observations\n",
      "test_fold_3 will have 177755 observations\n"
     ]
    }
   ],
   "source": [
    "# store indices for each split\n",
    "train_1_indices = np.arange(177755, len(df))\n",
    "test_1_indices = np.arange(0, 177755)\n",
    "train_2_indices = np.concatenate((np.arange(0, 177755), np.arange(177755*2, len(df))))\n",
    "test_2_indices = np.arange(177755, 177755*2)\n",
    "train_3_indices = np.arange(0, 177755*2)\n",
    "test_3_indices = np.arange(177755*2, len(df))\n",
    "\n",
    "# how many training observations in each fold?\n",
    "print('there are', len(df), 'observations in the training data')\n",
    "print('train_fold_1 will have', len(train_1_indices), 'observations')\n",
    "print('train_fold_2 will have', len(train_2_indices), 'observations')\n",
    "print('train_fold_3 will have', len(train_3_indices), 'observations')\n",
    "print('test_fold_1 will have', len(test_1_indices), 'observations')\n",
    "print('test_fold_2 will have', len(test_2_indices), 'observations')\n",
    "print('test_fold_3 will have', len(test_3_indices), 'observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_inputs(X_train, X_test):\n",
    "    '''\n",
    "    Standardize a train-test split using mean and standard deviation estimates from training data.\n",
    "    Returns a tuple of standardized training and test matrices.\n",
    "    '''\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(X_train)\n",
    "    X_train_scaled = scale.transform(X_train)\n",
    "    X_test_scaled = scale.transform(X_test)\n",
    "    return(X_train_scaled, X_test_scaled)\n",
    "\n",
    "def data_for_modeling(train_indices, test_indices, standardize = True, multi_input = False, multi_output = False, data = df, sequence = False):\n",
    "    '''\n",
    "    Get the training and test arrays for predictors and target to feed into your model.\n",
    "    Objects returned in a tuple in the following order: (X_train_objects, ..., X_test_objects, ..., y_train_objects, ..., y_test_objects)\n",
    "    Standardizes X appropriately, unless standardize = False, in which case X is not standardized.\n",
    "    If multi_input = True, multiple X objects are returned (to be used in wide and deep network).\n",
    "    If multi_output = True, multiple y objects are returned (to be used in multi-task network).\n",
    "    Does not support both multi_input and multi_output.\n",
    "    If sequence = True then each array is sorted by pid.\n",
    "    '''\n",
    "    # prepare target\n",
    "    if sequence:\n",
    "        y_train = df.iloc[train_indices].sort_values(by = ['pid'])['TAC_Reading_binary'].values\n",
    "        y_test = df.iloc[test_indices].sort_values(by = ['pid'])['TAC_Reading_binary'].values\n",
    "    else:\n",
    "        y_train = df.iloc[train_indices]['TAC_Reading_binary'].values\n",
    "        y_test = df.iloc[test_indices]['TAC_Reading_binary'].values\n",
    "    if multi_output:\n",
    "        y_train_classification = df.iloc[train_indices]['TAC_Reading_binary'].values\n",
    "        y_train_regression = df.iloc[train_indices]['TAC_Reading'].values\n",
    "        y_test_classification = df.iloc[test_indices]['TAC_Reading_binary'].values\n",
    "        y_test_regression = df.iloc[test_indices]['TAC_Reading'].values\n",
    "    \n",
    "    # prepare predictors\n",
    "    if sequence:\n",
    "        X_train = df.iloc[train_indices].sort_values(by = ['pid']).drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "        X_test = df.iloc[test_indices].sort_values(by = ['pid']).drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "    else:\n",
    "        X_train = df.iloc[train_indices].drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "        X_test = df.iloc[test_indices].drop(['time', 'pid', 'TAC_Reading', 'TAC_Reading_binary'], axis = 1)\n",
    "    if multi_input:\n",
    "        X_train_x = X_train['x'].values.reshape(-1,1)\n",
    "        X_train_y = X_train['y'].values.reshape(-1,1)\n",
    "        X_train_z = X_train['z'].values.reshape(-1,1)\n",
    "        X_train_p = X_train.drop(['x', 'y', 'z'], axis = 1)\n",
    "        X_test_x = X_test['x'].values.reshape(-1,1)\n",
    "        X_test_y = X_test['y'].values.reshape(-1,1)\n",
    "        X_test_z = X_test['z'].values.reshape(-1,1)\n",
    "        X_test_p = X_test.drop(['x', 'y', 'z'], axis = 1)\n",
    "    \n",
    "    # standardization\n",
    "    if standardize:\n",
    "        if multi_input:\n",
    "            X_train_x, X_test_x = standardize_inputs(X_train_x, X_test_x)\n",
    "            X_train_y, X_test_y = standardize_inputs(X_train_y, X_test_y)\n",
    "            X_train_z, X_test_z = standardize_inputs(X_train_z, X_test_z)\n",
    "            X_train_p, X_test_p = standardize_inputs(X_train_p, X_test_p)\n",
    "        else:\n",
    "            X_train_scaled, X_test_scaled = standardize_inputs(X_train, X_test)\n",
    "\n",
    "    # returns\n",
    "    if multi_input:\n",
    "        if standardize:\n",
    "            return(X_train_x, X_test_x, X_train_y, X_test_y, X_train_z, X_test_z, X_train_p, X_test_p, y_train, y_test)\n",
    "        else:\n",
    "            return(X_train_x, X_test_x, X_train_y, X_test_y, X_train_z, X_test_z, X_train_p, X_test_p, y_train, y_test)\n",
    "    elif multi_output:\n",
    "        if standardize:\n",
    "            return(X_train_scaled, X_test_scaled, y_train_classification, y_train_regression, y_test_classification, y_test_regression)\n",
    "        else:\n",
    "            return(X_train, X_test, y_train_classification, y_train_regression, y_test_classification, y_test_regression)\n",
    "    else:\n",
    "        if standardize:\n",
    "            return(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        else:\n",
    "            return(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "def format_test(y_test):\n",
    "    '''\n",
    "    Returns appropriately formatted y_test that can be used with output of model.predict() and sklearn scoring functions.\n",
    "    '''\n",
    "    y_test = y_test[np.arange(0, 177755, 20)]\n",
    "    y_test = y_test[0:len(y_test) - 1]\n",
    "    return(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors_batch shape is (128, 20, 99)\n",
      "labels_batch shape is (128,)\n"
     ]
    }
   ],
   "source": [
    "# verify that data is being sequenced and batched appropriately\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "data_inst = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20)\n",
    "\n",
    "for predictors_batch, labels_batch in data_inst:\n",
    "    print('predictors_batch shape is', predictors_batch.shape)\n",
    "    print('labels_batch shape is', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictors_batch shape is (128, 20, 99)\n",
      "labels_batch shape is (128,)\n"
     ]
    }
   ],
   "source": [
    "test_inst = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "for predictors_batch, labels_batch in test_inst:\n",
    "    print('predictors_batch shape is', predictors_batch.shape)\n",
    "    print('labels_batch shape is', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# containers to store results\n",
    "model = []\n",
    "fold = []\n",
    "accuracy = []\n",
    "precision_intox = []\n",
    "precision_sober = []\n",
    "recall_intox = []\n",
    "recall_sober = []\n",
    "support_sober = []\n",
    "support_intox = []\n",
    "\n",
    "results = {'model': model, 'fold': fold, 'accuracy' : accuracy, 'precision (intoxicated)': precision_intox,\n",
    "          'precision (sober)': precision_sober, 'recall (intoxicated)': recall_intox, 'recall (sober)': recall_sober, \n",
    "           'support (sober)': support_sober, 'support (intox)': support_intox}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(train_data, test_data, name):\n",
    "    '''\n",
    "    Creates an LSTM network and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.LSTM(units = 64, input_shape = [None, 99], return_sequences = True),\n",
    "        keras.layers.Dropout(rate = 0.1),\n",
    "        keras.layers.LSTM(units = 64, return_sequences = True),\n",
    "        keras.layers.Dropout(rate = 0.1),\n",
    "        keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "    ])\n",
    "    # compile model\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'lstm_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(x = train_data, epochs = 50, validation_data = test_data, callbacks = [lr_scheduler, checkpoint_cb, early_stopping_cb])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.2860 - accuracy: 0.8865 - val_loss: 0.9401 - val_accuracy: 0.5165\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.2380 - accuracy: 0.8959 - val_loss: 0.8947 - val_accuracy: 0.5275\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.2261 - accuracy: 0.8995 - val_loss: 0.9138 - val_accuracy: 0.5354\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.2143 - accuracy: 0.9045 - val_loss: 0.9517 - val_accuracy: 0.5387\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.1996 - accuracy: 0.9098 - val_loss: 0.9910 - val_accuracy: 0.5448\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.1859 - accuracy: 0.9158 - val_loss: 1.0320 - val_accuracy: 0.5513\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.1748 - accuracy: 0.9235 - val_loss: 1.0226 - val_accuracy: 0.5703\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.1607 - accuracy: 0.9279 - val_loss: 1.0657 - val_accuracy: 0.5740\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.1512 - accuracy: 0.9313 - val_loss: 1.1010 - val_accuracy: 0.5764\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.1438 - accuracy: 0.9343 - val_loss: 1.1346 - val_accuracy: 0.5784\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.1374 - accuracy: 0.9386 - val_loss: 1.1553 - val_accuracy: 0.5852\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.1328 - accuracy: 0.9408 - val_loss: 1.1759 - val_accuracy: 0.5868\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "lstm_1 = train_lstm(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = lstm_1.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['LSTM']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 49s 87ms/step - loss: 0.3573 - accuracy: 0.8310 - val_loss: 0.7929 - val_accuracy: 0.7019\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.3461 - accuracy: 0.8394 - val_loss: 0.6704 - val_accuracy: 0.7326\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.3335 - accuracy: 0.8466 - val_loss: 0.6226 - val_accuracy: 0.7419\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.3186 - accuracy: 0.8549 - val_loss: 0.6623 - val_accuracy: 0.7429\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 55s 100ms/step - loss: 0.3093 - accuracy: 0.8591 - val_loss: 0.6999 - val_accuracy: 0.7431\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.3035 - accuracy: 0.8627 - val_loss: 0.7121 - val_accuracy: 0.7438\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.2947 - accuracy: 0.8691 - val_loss: 0.7172 - val_accuracy: 0.7441\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 62s 112ms/step - loss: 0.3051 - accuracy: 0.8620 - val_loss: 0.6067 - val_accuracy: 0.7513\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 54s 98ms/step - loss: 0.2853 - accuracy: 0.8738 - val_loss: 0.6021 - val_accuracy: 0.7558\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 58s 105ms/step - loss: 0.2733 - accuracy: 0.8796 - val_loss: 0.6067 - val_accuracy: 0.7585\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.2632 - accuracy: 0.8845 - val_loss: 0.6144 - val_accuracy: 0.7599\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 64s 116ms/step - loss: 0.2539 - accuracy: 0.8889 - val_loss: 0.6241 - val_accuracy: 0.7599\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 65s 117ms/step - loss: 0.2449 - accuracy: 0.8926 - val_loss: 0.6355 - val_accuracy: 0.7605\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 65s 117ms/step - loss: 0.2395 - accuracy: 0.8936 - val_loss: 0.6035 - val_accuracy: 0.7798\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 68s 122ms/step - loss: 0.2333 - accuracy: 0.8960 - val_loss: 0.6022 - val_accuracy: 0.7807\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 66s 120ms/step - loss: 0.2278 - accuracy: 0.8987 - val_loss: 0.6070 - val_accuracy: 0.7806\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 66s 118ms/step - loss: 0.2235 - accuracy: 0.9008 - val_loss: 0.6134 - val_accuracy: 0.7802\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 66s 118ms/step - loss: 0.2196 - accuracy: 0.9015 - val_loss: 0.6037 - val_accuracy: 0.7897\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 61s 110ms/step - loss: 0.2176 - accuracy: 0.9027 - val_loss: 0.6026 - val_accuracy: 0.7895\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 62s 112ms/step - loss: 0.2153 - accuracy: 0.9040 - val_loss: 0.6045 - val_accuracy: 0.7895\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 56s 101ms/step - loss: 0.2138 - accuracy: 0.9048 - val_loss: 0.6071 - val_accuracy: 0.7893\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 63s 114ms/step - loss: 0.2112 - accuracy: 0.9052 - val_loss: 0.6051 - val_accuracy: 0.7911\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 57s 103ms/step - loss: 0.2102 - accuracy: 0.9059 - val_loss: 0.6049 - val_accuracy: 0.7912\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.2096 - accuracy: 0.9063 - val_loss: 0.6055 - val_accuracy: 0.7912\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "lstm_2 = train_lstm(train_data, test_data, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = lstm_2.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['LSTM']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5216 - accuracy: 0.7578 - val_loss: 0.7937 - val_accuracy: 0.5168\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.5120 - accuracy: 0.7602 - val_loss: 0.4413 - val_accuracy: 0.7885\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 58s 105ms/step - loss: 0.4946 - accuracy: 0.7673 - val_loss: 0.4848 - val_accuracy: 0.7756\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.4769 - accuracy: 0.7804 - val_loss: 0.4471 - val_accuracy: 0.8128\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.4635 - accuracy: 0.7866 - val_loss: 0.4450 - val_accuracy: 0.8172\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.4486 - accuracy: 0.7937 - val_loss: 0.4744 - val_accuracy: 0.7522\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 63s 113ms/step - loss: 0.4363 - accuracy: 0.8013 - val_loss: 0.4661 - val_accuracy: 0.6856\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 62s 111ms/step - loss: 0.4662 - accuracy: 0.7715 - val_loss: 0.3049 - val_accuracy: 0.8162\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.4496 - accuracy: 0.7784 - val_loss: 0.2860 - val_accuracy: 0.8330\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.4312 - accuracy: 0.7921 - val_loss: 0.2833 - val_accuracy: 0.8368\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 66s 119ms/step - loss: 0.4138 - accuracy: 0.8052 - val_loss: 0.2842 - val_accuracy: 0.8399\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 57s 103ms/step - loss: 0.3975 - accuracy: 0.8163 - val_loss: 0.2873 - val_accuracy: 0.8427\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 60s 108ms/step - loss: 0.3822 - accuracy: 0.8264 - val_loss: 0.2967 - val_accuracy: 0.8424\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 62s 111ms/step - loss: 0.3685 - accuracy: 0.8351 - val_loss: 0.3045 - val_accuracy: 0.8434\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.3565 - accuracy: 0.8421 - val_loss: 0.3073 - val_accuracy: 0.8467\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 56s 100ms/step - loss: 0.3554 - accuracy: 0.8434 - val_loss: 0.1872 - val_accuracy: 0.9134\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 57s 103ms/step - loss: 0.3442 - accuracy: 0.8477 - val_loss: 0.1780 - val_accuracy: 0.9196\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.3344 - accuracy: 0.8532 - val_loss: 0.1735 - val_accuracy: 0.9233\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.3270 - accuracy: 0.8579 - val_loss: 0.1715 - val_accuracy: 0.9254\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 55s 99ms/step - loss: 0.3203 - accuracy: 0.8616 - val_loss: 0.1694 - val_accuracy: 0.9276\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 54s 98ms/step - loss: 0.3143 - accuracy: 0.8646 - val_loss: 0.1678 - val_accuracy: 0.9292\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.3086 - accuracy: 0.8679 - val_loss: 0.1648 - val_accuracy: 0.9313\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.3034 - accuracy: 0.8704 - val_loss: 0.1586 - val_accuracy: 0.9351\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 64s 116ms/step - loss: 0.2984 - accuracy: 0.8730 - val_loss: 0.1567 - val_accuracy: 0.9362\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 60s 109ms/step - loss: 0.2932 - accuracy: 0.8758 - val_loss: 0.1521 - val_accuracy: 0.9388\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.2883 - accuracy: 0.8779 - val_loss: 0.1500 - val_accuracy: 0.9402\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 56s 100ms/step - loss: 0.2840 - accuracy: 0.8800 - val_loss: 0.1452 - val_accuracy: 0.9431\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 56s 101ms/step - loss: 0.2793 - accuracy: 0.8823 - val_loss: 0.1422 - val_accuracy: 0.9452\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 59s 106ms/step - loss: 0.2749 - accuracy: 0.8843 - val_loss: 0.1394 - val_accuracy: 0.9466\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 59s 105ms/step - loss: 0.2707 - accuracy: 0.8861 - val_loss: 0.1348 - val_accuracy: 0.9488\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.2675 - accuracy: 0.8874 - val_loss: 0.1348 - val_accuracy: 0.9488\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.2630 - accuracy: 0.8895 - val_loss: 0.1283 - val_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 56s 100ms/step - loss: 0.2591 - accuracy: 0.8911 - val_loss: 0.1267 - val_accuracy: 0.9525\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 59s 106ms/step - loss: 0.2555 - accuracy: 0.8928 - val_loss: 0.1181 - val_accuracy: 0.9561\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.2532 - accuracy: 0.8934 - val_loss: 0.1207 - val_accuracy: 0.9550\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.2494 - accuracy: 0.8954 - val_loss: 0.1187 - val_accuracy: 0.9551\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.2455 - accuracy: 0.8968 - val_loss: 0.1166 - val_accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.2434 - accuracy: 0.8976 - val_loss: 0.1061 - val_accuracy: 0.9605\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 55s 98ms/step - loss: 0.2406 - accuracy: 0.8988 - val_loss: 0.1106 - val_accuracy: 0.9590\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.2376 - accuracy: 0.8996 - val_loss: 0.1047 - val_accuracy: 0.9613\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 77s 138ms/step - loss: 0.2341 - accuracy: 0.9010 - val_loss: 0.1003 - val_accuracy: 0.9627\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.2309 - accuracy: 0.9023 - val_loss: 0.1047 - val_accuracy: 0.9618\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 93s 167ms/step - loss: 0.2279 - accuracy: 0.9032 - val_loss: 0.1085 - val_accuracy: 0.9602\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.2238 - accuracy: 0.9053 - val_loss: 0.1004 - val_accuracy: 0.9637\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.2208 - accuracy: 0.9063 - val_loss: 0.1031 - val_accuracy: 0.9627\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 64s 114ms/step - loss: 0.2187 - accuracy: 0.9070 - val_loss: 0.1027 - val_accuracy: 0.9615\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 63s 112ms/step - loss: 0.2192 - accuracy: 0.9059 - val_loss: 0.1004 - val_accuracy: 0.9654\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 61s 109ms/step - loss: 0.2187 - accuracy: 0.9059 - val_loss: 0.0952 - val_accuracy: 0.9675\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 59s 107ms/step - loss: 0.2148 - accuracy: 0.9075 - val_loss: 0.0938 - val_accuracy: 0.9687\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 57s 103ms/step - loss: 0.2123 - accuracy: 0.9089 - val_loss: 0.0938 - val_accuracy: 0.9685\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "lstm_3 = train_lstm(train_data, test_data, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = lstm_3.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['LSTM']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Convolution + RNN (with GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_rnn(train_data, test_data, name):\n",
    "    '''\n",
    "    Creates a network with a convolutional layer followed by 2 recurrent layers.\n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv1D(filters = 30, kernel_size = 4, strides = 1, padding = 'same', input_shape = [None, 99]),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.GRU(units = 30, return_sequences = True),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.GRU(units = 30),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "    ])\n",
    "    # compile model\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'conv_rnn_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(x = train_data, epochs = 50, validation_data = test_data, callbacks = [lr_scheduler, checkpoint_cb, early_stopping_cb])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.2592 - accuracy: 0.9049 - val_loss: 1.6386 - val_accuracy: 0.5068\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 35s 63ms/step - loss: 0.2258 - accuracy: 0.9205 - val_loss: 1.8637 - val_accuracy: 0.4736\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 36s 64ms/step - loss: 0.2059 - accuracy: 0.9184 - val_loss: 2.0185 - val_accuracy: 0.4771\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 36s 66ms/step - loss: 0.2031 - accuracy: 0.9225 - val_loss: 2.0515 - val_accuracy: 0.4795\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.2297 - accuracy: 0.9183 - val_loss: 2.4274 - val_accuracy: 0.4787\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.2263 - accuracy: 0.9218 - val_loss: 2.3696 - val_accuracy: 0.4749\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.2727 - accuracy: 0.8921 - val_loss: 1.2799 - val_accuracy: 0.4674\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.2303 - accuracy: 0.9002 - val_loss: 1.1651 - val_accuracy: 0.4912\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.2204 - accuracy: 0.9010 - val_loss: 1.0425 - val_accuracy: 0.5190\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 39s 71ms/step - loss: 0.2094 - accuracy: 0.9058 - val_loss: 0.9898 - val_accuracy: 0.5481\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 38s 68ms/step - loss: 0.2029 - accuracy: 0.9092 - val_loss: 0.9635 - val_accuracy: 0.5603\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.1926 - accuracy: 0.9182 - val_loss: 0.9529 - val_accuracy: 0.5667\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 34s 62ms/step - loss: 0.1826 - accuracy: 0.9243 - val_loss: 0.9385 - val_accuracy: 0.5670\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 39s 70ms/step - loss: 0.1731 - accuracy: 0.9298 - val_loss: 0.9366 - val_accuracy: 0.5716\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.1646 - accuracy: 0.9353 - val_loss: 0.9439 - val_accuracy: 0.5784\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.1578 - accuracy: 0.9386 - val_loss: 0.9549 - val_accuracy: 0.5830\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 43s 78ms/step - loss: 0.1501 - accuracy: 0.9410 - val_loss: 0.9556 - val_accuracy: 0.5865\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 43s 77ms/step - loss: 0.1452 - accuracy: 0.9438 - val_loss: 0.9798 - val_accuracy: 0.5896\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.1372 - accuracy: 0.9470 - val_loss: 1.0092 - val_accuracy: 0.5926\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.1302 - accuracy: 0.9466 - val_loss: 1.0820 - val_accuracy: 0.6049\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 45s 81ms/step - loss: 0.1228 - accuracy: 0.9494 - val_loss: 1.0937 - val_accuracy: 0.6063\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.1182 - accuracy: 0.9520 - val_loss: 1.1026 - val_accuracy: 0.6055\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.1148 - accuracy: 0.9533 - val_loss: 1.1117 - val_accuracy: 0.6064\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 44s 79ms/step - loss: 0.1109 - accuracy: 0.9560 - val_loss: 1.1254 - val_accuracy: 0.6079\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.1062 - accuracy: 0.9569 - val_loss: 1.1899 - val_accuracy: 0.6089\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 45s 82ms/step - loss: 0.1040 - accuracy: 0.9583 - val_loss: 1.1898 - val_accuracy: 0.6108\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.1007 - accuracy: 0.9594 - val_loss: 1.2030 - val_accuracy: 0.6111\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.0995 - accuracy: 0.9598 - val_loss: 1.2172 - val_accuracy: 0.6106\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.0973 - accuracy: 0.9606 - val_loss: 1.2293 - val_accuracy: 0.6107\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_rnn_1 = train_conv_rnn(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = conv_rnn_1.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['convolutional + recurrent network']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 44s 79ms/step - loss: 0.3195 - accuracy: 0.8576 - val_loss: 1.1934 - val_accuracy: 0.6320\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.3156 - accuracy: 0.8748 - val_loss: 1.5486 - val_accuracy: 0.5824\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.3073 - accuracy: 0.8789 - val_loss: 1.2150 - val_accuracy: 0.6747\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 38s 68ms/step - loss: 0.2981 - accuracy: 0.8804 - val_loss: 1.1955 - val_accuracy: 0.6298\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.2845 - accuracy: 0.8859 - val_loss: 1.2108 - val_accuracy: 0.6273\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 40s 73ms/step - loss: 0.2778 - accuracy: 0.8877 - val_loss: 1.0280 - val_accuracy: 0.6909\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 39s 69ms/step - loss: 0.2794 - accuracy: 0.8877 - val_loss: 0.9950 - val_accuracy: 0.6838\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.2797 - accuracy: 0.8880 - val_loss: 0.8630 - val_accuracy: 0.7181\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 39s 70ms/step - loss: 0.2834 - accuracy: 0.8846 - val_loss: 0.7991 - val_accuracy: 0.7410\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.2825 - accuracy: 0.8847 - val_loss: 0.8395 - val_accuracy: 0.7352\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.2730 - accuracy: 0.8904 - val_loss: 0.7868 - val_accuracy: 0.7387\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 44s 78ms/step - loss: 0.2814 - accuracy: 0.8882 - val_loss: 0.7870 - val_accuracy: 0.7378\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.2758 - accuracy: 0.8878 - val_loss: 0.7748 - val_accuracy: 0.7392\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.2747 - accuracy: 0.8871 - val_loss: 0.8212 - val_accuracy: 0.7339\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.2723 - accuracy: 0.8904 - val_loss: 0.7936 - val_accuracy: 0.7409\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.2698 - accuracy: 0.8928 - val_loss: 0.7559 - val_accuracy: 0.7450\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.2658 - accuracy: 0.8939 - val_loss: 0.7643 - val_accuracy: 0.7416\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.2623 - accuracy: 0.8961 - val_loss: 0.7663 - val_accuracy: 0.7407\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 43s 76ms/step - loss: 0.2592 - accuracy: 0.8968 - val_loss: 0.7478 - val_accuracy: 0.7362\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.2562 - accuracy: 0.8983 - val_loss: 0.7188 - val_accuracy: 0.7369\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 39s 70ms/step - loss: 0.2510 - accuracy: 0.9008 - val_loss: 0.6982 - val_accuracy: 0.7396\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 39s 70ms/step - loss: 0.2438 - accuracy: 0.9039 - val_loss: 0.6879 - val_accuracy: 0.7403\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.2358 - accuracy: 0.9068 - val_loss: 0.6902 - val_accuracy: 0.7402\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 39s 70ms/step - loss: 0.2273 - accuracy: 0.9091 - val_loss: 0.6839 - val_accuracy: 0.7404\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 34s 61ms/step - loss: 0.2203 - accuracy: 0.9121 - val_loss: 0.6937 - val_accuracy: 0.7370\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.2142 - accuracy: 0.9132 - val_loss: 0.7058 - val_accuracy: 0.7389\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 32s 58ms/step - loss: 0.2078 - accuracy: 0.9149 - val_loss: 0.7158 - val_accuracy: 0.7428\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 32s 58ms/step - loss: 0.2031 - accuracy: 0.9178 - val_loss: 0.7358 - val_accuracy: 0.7402\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.1966 - accuracy: 0.9189 - val_loss: 0.7622 - val_accuracy: 0.7424\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 31s 57ms/step - loss: 0.2021 - accuracy: 0.9151 - val_loss: 0.7225 - val_accuracy: 0.7526\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.1977 - accuracy: 0.9169 - val_loss: 0.7256 - val_accuracy: 0.7542\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.1923 - accuracy: 0.9182 - val_loss: 0.7332 - val_accuracy: 0.7572\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.1881 - accuracy: 0.9196 - val_loss: 0.7441 - val_accuracy: 0.7541\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 33s 59ms/step - loss: 0.1814 - accuracy: 0.9219 - val_loss: 0.7620 - val_accuracy: 0.7553\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 39s 71ms/step - loss: 0.1842 - accuracy: 0.9207 - val_loss: 0.7524 - val_accuracy: 0.7706\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 38s 68ms/step - loss: 0.1813 - accuracy: 0.9212 - val_loss: 0.7455 - val_accuracy: 0.7759\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 35s 63ms/step - loss: 0.1781 - accuracy: 0.9216 - val_loss: 0.7398 - val_accuracy: 0.7804\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 34s 61ms/step - loss: 0.1743 - accuracy: 0.9229 - val_loss: 0.7409 - val_accuracy: 0.7799\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.1713 - accuracy: 0.9246 - val_loss: 0.7457 - val_accuracy: 0.7833\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_rnn_2 = train_conv_rnn(train_data, test_data, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = conv_rnn_2.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['convolutional + recurrent network']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 39s 71ms/step - loss: 0.4946 - accuracy: 0.7638 - val_loss: 1.1328 - val_accuracy: 0.5651\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.4841 - accuracy: 0.7760 - val_loss: 0.7366 - val_accuracy: 0.7056\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 40s 71ms/step - loss: 0.4617 - accuracy: 0.7903 - val_loss: 0.6905 - val_accuracy: 0.7016\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.4540 - accuracy: 0.7974 - val_loss: 0.5884 - val_accuracy: 0.7524\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.4335 - accuracy: 0.8114 - val_loss: 0.5877 - val_accuracy: 0.7766\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 43s 77ms/step - loss: 0.4485 - accuracy: 0.8007 - val_loss: 0.6045 - val_accuracy: 0.7693\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 38s 69ms/step - loss: 0.4504 - accuracy: 0.7964 - val_loss: 0.5814 - val_accuracy: 0.7493\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 38s 68ms/step - loss: 0.4535 - accuracy: 0.7878 - val_loss: 0.7011 - val_accuracy: 0.6845\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.4534 - accuracy: 0.7948 - val_loss: 0.4256 - val_accuracy: 0.8059\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 46s 83ms/step - loss: 0.4522 - accuracy: 0.7924 - val_loss: 0.7548 - val_accuracy: 0.5762\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.4448 - accuracy: 0.7966 - val_loss: 1.3510 - val_accuracy: 0.1377\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 46s 83ms/step - loss: 0.4437 - accuracy: 0.7986 - val_loss: 0.9075 - val_accuracy: 0.5190\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.4439 - accuracy: 0.7942 - val_loss: 0.7333 - val_accuracy: 0.6735\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 39s 69ms/step - loss: 0.4488 - accuracy: 0.7940 - val_loss: 0.6180 - val_accuracy: 0.7438\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 46s 83ms/step - loss: 0.5156 - accuracy: 0.7563 - val_loss: 0.2508 - val_accuracy: 0.9366\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.4900 - accuracy: 0.7727 - val_loss: 0.1962 - val_accuracy: 0.9571\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.4798 - accuracy: 0.7764 - val_loss: 0.2197 - val_accuracy: 0.9480\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 45s 82ms/step - loss: 0.4654 - accuracy: 0.7846 - val_loss: 0.2482 - val_accuracy: 0.9400\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 40s 72ms/step - loss: 0.4551 - accuracy: 0.7930 - val_loss: 0.2190 - val_accuracy: 0.9525\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 36s 64ms/step - loss: 0.4518 - accuracy: 0.7914 - val_loss: 0.1864 - val_accuracy: 0.9642\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 39s 69ms/step - loss: 0.4471 - accuracy: 0.7923 - val_loss: 0.1883 - val_accuracy: 0.9640\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.4401 - accuracy: 0.7987 - val_loss: 0.1873 - val_accuracy: 0.9668\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 35s 63ms/step - loss: 0.4351 - accuracy: 0.8046 - val_loss: 0.1831 - val_accuracy: 0.9649\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.4271 - accuracy: 0.8080 - val_loss: 0.1841 - val_accuracy: 0.9549\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 39s 71ms/step - loss: 0.4231 - accuracy: 0.8110 - val_loss: 0.2032 - val_accuracy: 0.9384\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 40s 73ms/step - loss: 0.4206 - accuracy: 0.8110 - val_loss: 0.2335 - val_accuracy: 0.9244\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 37s 67ms/step - loss: 0.4151 - accuracy: 0.8128 - val_loss: 0.2372 - val_accuracy: 0.9239\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.4112 - accuracy: 0.8160 - val_loss: 0.2263 - val_accuracy: 0.9284\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 38s 68ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.1620 - val_accuracy: 0.9360\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 38s 67ms/step - loss: 0.4259 - accuracy: 0.8047 - val_loss: 0.1691 - val_accuracy: 0.9302\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.4167 - accuracy: 0.8111 - val_loss: 0.1762 - val_accuracy: 0.9243\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.4069 - accuracy: 0.8157 - val_loss: 0.1733 - val_accuracy: 0.9266\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.3987 - accuracy: 0.8216 - val_loss: 0.1740 - val_accuracy: 0.9248\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 34s 61ms/step - loss: 0.3922 - accuracy: 0.8245 - val_loss: 0.1702 - val_accuracy: 0.9274\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 37s 67ms/step - loss: 0.3930 - accuracy: 0.8258 - val_loss: 0.1415 - val_accuracy: 0.9444\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.3834 - accuracy: 0.8291 - val_loss: 0.1365 - val_accuracy: 0.9489\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 35s 63ms/step - loss: 0.3772 - accuracy: 0.8323 - val_loss: 0.1376 - val_accuracy: 0.9472\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.3714 - accuracy: 0.8367 - val_loss: 0.1365 - val_accuracy: 0.9468\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 32s 57ms/step - loss: 0.3683 - accuracy: 0.8358 - val_loss: 0.1320 - val_accuracy: 0.9525\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.3643 - accuracy: 0.8395 - val_loss: 0.1321 - val_accuracy: 0.9515\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 33s 59ms/step - loss: 0.3604 - accuracy: 0.8413 - val_loss: 0.1310 - val_accuracy: 0.9525\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 36s 66ms/step - loss: 0.3566 - accuracy: 0.8425 - val_loss: 0.1331 - val_accuracy: 0.9502\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 37s 67ms/step - loss: 0.3534 - accuracy: 0.8438 - val_loss: 0.1297 - val_accuracy: 0.9526\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 36s 64ms/step - loss: 0.3498 - accuracy: 0.8450 - val_loss: 0.1347 - val_accuracy: 0.9488\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.3472 - accuracy: 0.8466 - val_loss: 0.1327 - val_accuracy: 0.9494\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 36s 65ms/step - loss: 0.3431 - accuracy: 0.8488 - val_loss: 0.1356 - val_accuracy: 0.9468\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 36s 64ms/step - loss: 0.3400 - accuracy: 0.8505 - val_loss: 0.1337 - val_accuracy: 0.9490\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 35s 64ms/step - loss: 0.3366 - accuracy: 0.8516 - val_loss: 0.1347 - val_accuracy: 0.9478\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 37s 66ms/step - loss: 0.3343 - accuracy: 0.8528 - val_loss: 0.1132 - val_accuracy: 0.9604\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 39s 71ms/step - loss: 0.3318 - accuracy: 0.8543 - val_loss: 0.1124 - val_accuracy: 0.9607\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_rnn_3 = train_conv_rnn(train_data, test_data, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = conv_rnn_3.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['convolutional + recurrent network']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wavenet(train_data, test_data, name):\n",
    "    '''\n",
    "    Creates wavenet network (stacked 1D convolutional networks).\n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify architecture\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = [None, 99]))\n",
    "    for rate in (1, 2, 4, 8) * 2:\n",
    "        model.add(keras.layers.Conv1D(filters = 30, kernel_size = 2, padding = 'causal', activation= 'relu', dilation_rate=rate))\n",
    "    for rate in (1, 2, 4, 8) * 2:\n",
    "        model.add(keras.layers.Conv1D(filters = 30, kernel_size = 2, padding = 'causal', activation= 'relu', dilation_rate=rate))\n",
    "    model.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "    \n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'wavenet_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    # compile model\n",
    "    \n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(x = train_data, epochs = 50, validation_data = test_data, callbacks = [lr_scheduler, checkpoint_cb, early_stopping_cb])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.3970 - accuracy: 0.8748 - val_loss: 0.9509 - val_accuracy: 0.5438\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.4132 - accuracy: 0.8619 - val_loss: 0.9820 - val_accuracy: 0.5438\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.4144 - accuracy: 0.8619 - val_loss: 0.9820 - val_accuracy: 0.5438\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4144 - accuracy: 0.8619 - val_loss: 0.9820 - val_accuracy: 0.5438\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.4144 - accuracy: 0.8619 - val_loss: 0.9820 - val_accuracy: 0.5438\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.4144 - accuracy: 0.8619 - val_loss: 0.9820 - val_accuracy: 0.5438\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.4154 - accuracy: 0.8619 - val_loss: 1.0386 - val_accuracy: 0.5438\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.4150 - accuracy: 0.8619 - val_loss: 1.0434 - val_accuracy: 0.5438\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.4152 - accuracy: 0.8619 - val_loss: 1.0436 - val_accuracy: 0.5438\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.4152 - accuracy: 0.8619 - val_loss: 1.0436 - val_accuracy: 0.5438\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.4152 - accuracy: 0.8619 - val_loss: 1.0436 - val_accuracy: 0.5438\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.4126 - accuracy: 0.8619 - val_loss: 1.0274 - val_accuracy: 0.5438\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.4110 - accuracy: 0.8619 - val_loss: 1.0339 - val_accuracy: 0.5438\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4112 - accuracy: 0.8619 - val_loss: 1.0351 - val_accuracy: 0.5438\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.4112 - accuracy: 0.8619 - val_loss: 1.0353 - val_accuracy: 0.5438\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 59s 106ms/step - loss: 0.4112 - accuracy: 0.8619 - val_loss: 1.0353 - val_accuracy: 0.5438\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "wavenet_1 = train_wavenet(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = wavenet_1.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "record results\n",
    "model += ['simplified wavenet']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 63s 112ms/step - loss: 0.4949 - accuracy: 0.7581 - val_loss: 0.6337 - val_accuracy: 0.7203\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.5308 - accuracy: 0.7375 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.5309 - accuracy: 0.7318 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 55s 99ms/step - loss: 0.5500 - accuracy: 0.7478 - val_loss: 0.5936 - val_accuracy: 0.7203\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 58s 105ms/step - loss: 0.5466 - accuracy: 0.7712 - val_loss: 0.5937 - val_accuracy: 0.7203\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.5466 - accuracy: 0.7712 - val_loss: 0.5937 - val_accuracy: 0.7203\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 57s 102ms/step - loss: 0.5466 - accuracy: 0.7712 - val_loss: 0.5937 - val_accuracy: 0.7203\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.5466 - accuracy: 0.7712 - val_loss: 0.5937 - val_accuracy: 0.7203\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5466 - accuracy: 0.7712 - val_loss: 0.5937 - val_accuracy: 0.7203\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.5501 - accuracy: 0.7712 - val_loss: 0.5969 - val_accuracy: 0.7203\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.5478 - accuracy: 0.7712 - val_loss: 0.5977 - val_accuracy: 0.7203\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.5477 - accuracy: 0.7712 - val_loss: 0.5978 - val_accuracy: 0.7203\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.5477 - accuracy: 0.7712 - val_loss: 0.5978 - val_accuracy: 0.7203\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.5477 - accuracy: 0.7712 - val_loss: 0.5978 - val_accuracy: 0.7203\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.5457 - accuracy: 0.7712 - val_loss: 0.5980 - val_accuracy: 0.7203\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5447 - accuracy: 0.7712 - val_loss: 0.5991 - val_accuracy: 0.7203\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.5446 - accuracy: 0.7712 - val_loss: 0.5994 - val_accuracy: 0.7203\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.5445 - accuracy: 0.7712 - val_loss: 0.5995 - val_accuracy: 0.7203\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.5445 - accuracy: 0.7712 - val_loss: 0.5996 - val_accuracy: 0.7203\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "wavenet_2 = train_wavenet(train_data, test_data, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = wavenet_2.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['simplified wavenet']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 55s 99ms/step - loss: 0.6193 - accuracy: 0.6606 - val_loss: 1.0593 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 1.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 1.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 1.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 1.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.6284 - accuracy: 0.6426 - val_loss: 1.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6626 - accuracy: 0.6283 - val_loss: 0.6606 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6599 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.6683 - accuracy: 0.6212 - val_loss: 0.5178 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.6637 - accuracy: 0.6140 - val_loss: 0.5111 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 55s 99ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.6637 - accuracy: 0.6144 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.6660 - accuracy: 0.6329 - val_loss: 0.4790 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.6642 - accuracy: 0.6329 - val_loss: 0.4682 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4661 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4658 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.6641 - accuracy: 0.6329 - val_loss: 0.4657 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.6623 - accuracy: 0.6329 - val_loss: 0.4660 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4607 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4583 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 49s 87ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4573 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4569 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4567 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 60s 108ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4566 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 46s 82ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 56s 102ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 53s 94ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.6618 - accuracy: 0.6329 - val_loss: 0.4565 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.6600 - accuracy: 0.6329 - val_loss: 0.4603 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.6599 - accuracy: 0.6329 - val_loss: 0.4589 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.6599 - accuracy: 0.6329 - val_loss: 0.4579 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.6598 - accuracy: 0.6329 - val_loss: 0.4573 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.6598 - accuracy: 0.6329 - val_loss: 0.4569 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.6588 - accuracy: 0.6329 - val_loss: 0.4593 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 51s 93ms/step - loss: 0.6587 - accuracy: 0.6329 - val_loss: 0.4588 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-360c7b865f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprecision_intox\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprecision_sober\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mrecall_intox\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "wavenet_3 = train_wavenet(train_data, test_data, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = wavenet_3.predict(test_data)\n",
    "pred_prob = pred_prob[:, -1, :]\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "#record results\n",
    "model += ['simplified wavenet']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.append('simplified wavenet')\n",
    "fold.append(3)\n",
    "accuracy.append(1.00)\n",
    "precision_intox.append(1.00)\n",
    "precision_sober.append(1.00)\n",
    "recall_intox.append(1.00)\n",
    "recall_sober.append(1.00)\n",
    "support_sober.append(8887)\n",
    "support_intox.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4 Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bi_lstm(train_data, test_data, name):\n",
    "    '''\n",
    "    Creates an bidirectional LSTM network and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units = 64, return_sequences = True), input_shape = [None, 99]),\n",
    "        keras.layers.Dropout(rate = 0.1),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units = 64)),\n",
    "        keras.layers.Dropout(rate = 0.1),\n",
    "        keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "    ])\n",
    "    # compile model\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'bi_lstm_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(x = train_data, epochs = 50, validation_data = test_data, callbacks = [lr_scheduler, checkpoint_cb, early_stopping_cb])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 81s 146ms/step - loss: 0.2598 - accuracy: 0.9001 - val_loss: 1.3373 - val_accuracy: 0.4848\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 91s 163ms/step - loss: 0.2283 - accuracy: 0.9090 - val_loss: 1.3431 - val_accuracy: 0.4907\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 102s 184ms/step - loss: 0.2157 - accuracy: 0.9127 - val_loss: 1.0977 - val_accuracy: 0.5068\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 83s 150ms/step - loss: 0.2064 - accuracy: 0.9110 - val_loss: 0.9494 - val_accuracy: 0.5188\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 90s 161ms/step - loss: 0.1854 - accuracy: 0.9172 - val_loss: 0.9631 - val_accuracy: 0.5340\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 91s 164ms/step - loss: 0.1676 - accuracy: 0.9247 - val_loss: 1.0272 - val_accuracy: 0.5474\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 106s 191ms/step - loss: 0.1545 - accuracy: 0.9323 - val_loss: 1.0940 - val_accuracy: 0.5582\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 89s 160ms/step - loss: 0.1372 - accuracy: 0.9402 - val_loss: 1.1482 - val_accuracy: 0.5681\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 97s 175ms/step - loss: 0.1199 - accuracy: 0.9470 - val_loss: 1.2110 - val_accuracy: 0.5726\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.1036 - accuracy: 0.9553 - val_loss: 1.2615 - val_accuracy: 0.5927\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 96s 172ms/step - loss: 0.0900 - accuracy: 0.9619 - val_loss: 1.3198 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 94s 170ms/step - loss: 0.0811 - accuracy: 0.9657 - val_loss: 1.3762 - val_accuracy: 0.6013\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 96s 172ms/step - loss: 0.0745 - accuracy: 0.9687 - val_loss: 1.4340 - val_accuracy: 0.6032\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 103s 186ms/step - loss: 0.0684 - accuracy: 0.9713 - val_loss: 1.4914 - val_accuracy: 0.6039\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 120s 216ms/step - loss: 0.0623 - accuracy: 0.9736 - val_loss: 1.5561 - val_accuracy: 0.6091\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 117s 211ms/step - loss: 0.0583 - accuracy: 0.9760 - val_loss: 1.5802 - val_accuracy: 0.6098\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 108s 194ms/step - loss: 0.0546 - accuracy: 0.9781 - val_loss: 1.6146 - val_accuracy: 0.6113\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 110s 197ms/step - loss: 0.0516 - accuracy: 0.9794 - val_loss: 1.6447 - val_accuracy: 0.6107\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 118s 212ms/step - loss: 0.0491 - accuracy: 0.9800 - val_loss: 1.6789 - val_accuracy: 0.6104\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "bi_lstm_1 = train_bi_lstm(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = bi_lstm_1.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['bi-LSTM']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 107s 192ms/step - loss: 0.3027 - accuracy: 0.8697 - val_loss: 0.9441 - val_accuracy: 0.6598\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 86s 155ms/step - loss: 0.3034 - accuracy: 0.8771 - val_loss: 0.9171 - val_accuracy: 0.6178\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 88s 158ms/step - loss: 0.3005 - accuracy: 0.8716 - val_loss: 0.8386 - val_accuracy: 0.6531\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 101s 181ms/step - loss: 0.2908 - accuracy: 0.8765 - val_loss: 0.6801 - val_accuracy: 0.7358\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 91s 163ms/step - loss: 0.2818 - accuracy: 0.8804 - val_loss: 0.6614 - val_accuracy: 0.7463\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 91s 163ms/step - loss: 0.2718 - accuracy: 0.8841 - val_loss: 0.6925 - val_accuracy: 0.7494\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 92s 166ms/step - loss: 0.2627 - accuracy: 0.8901 - val_loss: 0.7135 - val_accuracy: 0.7504\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 105s 189ms/step - loss: 0.2499 - accuracy: 0.8960 - val_loss: 0.7681 - val_accuracy: 0.7492\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 82s 148ms/step - loss: 0.2367 - accuracy: 0.9023 - val_loss: 0.8023 - val_accuracy: 0.7522\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 125s 224ms/step - loss: 0.2247 - accuracy: 0.9054 - val_loss: 0.8187 - val_accuracy: 0.7486\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 122s 220ms/step - loss: 0.2280 - accuracy: 0.8998 - val_loss: 0.6497 - val_accuracy: 0.7751\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 109s 196ms/step - loss: 0.2082 - accuracy: 0.9079 - val_loss: 0.6718 - val_accuracy: 0.7737\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 97s 175ms/step - loss: 0.1934 - accuracy: 0.9148 - val_loss: 0.6966 - val_accuracy: 0.7756\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 111s 200ms/step - loss: 0.1829 - accuracy: 0.9184 - val_loss: 0.7128 - val_accuracy: 0.7732\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 124s 222ms/step - loss: 0.1725 - accuracy: 0.9222 - val_loss: 0.7264 - val_accuracy: 0.7720\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 104s 188ms/step - loss: 0.1634 - accuracy: 0.9252 - val_loss: 0.7398 - val_accuracy: 0.7717\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 180s 324ms/step - loss: 0.1583 - accuracy: 0.9261 - val_loss: 0.7122 - val_accuracy: 0.7747\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 127s 229ms/step - loss: 0.1535 - accuracy: 0.9293 - val_loss: 0.7105 - val_accuracy: 0.7760\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 107s 193ms/step - loss: 0.1490 - accuracy: 0.9313 - val_loss: 0.7121 - val_accuracy: 0.7780\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 127s 228ms/step - loss: 0.1441 - accuracy: 0.9339 - val_loss: 0.7148 - val_accuracy: 0.7800\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 119s 214ms/step - loss: 0.1405 - accuracy: 0.9357 - val_loss: 0.7175 - val_accuracy: 0.7832\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 177s 319ms/step - loss: 0.1384 - accuracy: 0.9357 - val_loss: 0.7029 - val_accuracy: 0.7879\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 122s 219ms/step - loss: 0.1346 - accuracy: 0.9387 - val_loss: 0.7006 - val_accuracy: 0.7886\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 131s 235ms/step - loss: 0.1324 - accuracy: 0.9401 - val_loss: 0.7014 - val_accuracy: 0.7891\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 116s 208ms/step - loss: 0.1300 - accuracy: 0.9408 - val_loss: 0.7025 - val_accuracy: 0.7892\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 123s 222ms/step - loss: 0.1281 - accuracy: 0.9420 - val_loss: 0.7053 - val_accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "bi_lstm_2 = train_bi_lstm(train_data, test_data, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = bi_lstm_2.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['bi-LSTM']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 120s 215ms/step - loss: 0.4936 - accuracy: 0.7722 - val_loss: 1.1744 - val_accuracy: 0.1874\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 98s 176ms/step - loss: 0.4684 - accuracy: 0.7890 - val_loss: 0.4161 - val_accuracy: 0.8945\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 83s 149ms/step - loss: 0.4536 - accuracy: 0.7931 - val_loss: 0.3432 - val_accuracy: 0.9110\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 82s 148ms/step - loss: 0.4445 - accuracy: 0.7998 - val_loss: 0.4049 - val_accuracy: 0.8480\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 96s 173ms/step - loss: 0.4235 - accuracy: 0.8097 - val_loss: 0.4183 - val_accuracy: 0.8024\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 84s 151ms/step - loss: 0.3992 - accuracy: 0.8232 - val_loss: 0.5523 - val_accuracy: 0.7432\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 83s 150ms/step - loss: 0.3740 - accuracy: 0.8328 - val_loss: 0.9916 - val_accuracy: 0.5784\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 83s 150ms/step - loss: 0.3615 - accuracy: 0.8431 - val_loss: 0.6604 - val_accuracy: 0.6623\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 83s 149ms/step - loss: 0.3859 - accuracy: 0.8259 - val_loss: 0.4977 - val_accuracy: 0.7193\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 84s 151ms/step - loss: 0.3437 - accuracy: 0.8462 - val_loss: 0.5096 - val_accuracy: 0.7271\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 83s 149ms/step - loss: 0.3249 - accuracy: 0.8558 - val_loss: 0.4898 - val_accuracy: 0.7648\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 85s 153ms/step - loss: 0.3035 - accuracy: 0.8665 - val_loss: 0.4457 - val_accuracy: 0.7925\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 90s 161ms/step - loss: 0.2902 - accuracy: 0.8725 - val_loss: 0.4012 - val_accuracy: 0.8281\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 113s 204ms/step - loss: 0.2999 - accuracy: 0.8682 - val_loss: 0.2959 - val_accuracy: 0.8703\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 80s 143ms/step - loss: 0.2791 - accuracy: 0.8771 - val_loss: 0.3295 - val_accuracy: 0.8556\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 79s 142ms/step - loss: 0.2630 - accuracy: 0.8849 - val_loss: 0.3277 - val_accuracy: 0.8593\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 113s 204ms/step - loss: 0.2521 - accuracy: 0.8906 - val_loss: 0.3520 - val_accuracy: 0.8532\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 147s 264ms/step - loss: 0.2441 - accuracy: 0.8936 - val_loss: 0.3857 - val_accuracy: 0.8453\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 128s 230ms/step - loss: 0.2525 - accuracy: 0.8877 - val_loss: 0.5019 - val_accuracy: 0.8206\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 96s 173ms/step - loss: 0.2569 - accuracy: 0.8878 - val_loss: 0.2392 - val_accuracy: 0.9005\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 129s 232ms/step - loss: 0.2466 - accuracy: 0.8928 - val_loss: 0.1974 - val_accuracy: 0.9184\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 114s 204ms/step - loss: 0.2377 - accuracy: 0.8985 - val_loss: 0.1718 - val_accuracy: 0.9260\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 184s 331ms/step - loss: 0.2297 - accuracy: 0.9017 - val_loss: 0.1537 - val_accuracy: 0.9327\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 168s 303ms/step - loss: 0.2223 - accuracy: 0.9057 - val_loss: 0.1446 - val_accuracy: 0.9357\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 107s 192ms/step - loss: 0.2151 - accuracy: 0.9093 - val_loss: 0.1297 - val_accuracy: 0.9416\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 148s 267ms/step - loss: 0.2087 - accuracy: 0.9123 - val_loss: 0.1282 - val_accuracy: 0.9423\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 126s 227ms/step - loss: 0.2030 - accuracy: 0.9149 - val_loss: 0.1217 - val_accuracy: 0.9457\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 159s 286ms/step - loss: 0.1981 - accuracy: 0.9170 - val_loss: 0.1192 - val_accuracy: 0.9466\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 117s 211ms/step - loss: 0.1915 - accuracy: 0.9197 - val_loss: 0.1140 - val_accuracy: 0.9486\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 208s 374ms/step - loss: 0.1865 - accuracy: 0.9219 - val_loss: 0.1117 - val_accuracy: 0.9494\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 196s 353ms/step - loss: 0.1809 - accuracy: 0.9246 - val_loss: 0.1109 - val_accuracy: 0.9500\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 160s 287ms/step - loss: 0.1761 - accuracy: 0.9268 - val_loss: 0.1068 - val_accuracy: 0.9523\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 145s 261ms/step - loss: 0.1718 - accuracy: 0.9287 - val_loss: 0.1084 - val_accuracy: 0.9512\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 176s 316ms/step - loss: 0.1674 - accuracy: 0.9308 - val_loss: 0.1033 - val_accuracy: 0.9544\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 182s 326ms/step - loss: 0.1634 - accuracy: 0.9328 - val_loss: 0.1062 - val_accuracy: 0.9536\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 139s 250ms/step - loss: 0.1589 - accuracy: 0.9348 - val_loss: 0.1036 - val_accuracy: 0.9545\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 120s 215ms/step - loss: 0.1544 - accuracy: 0.9369 - val_loss: 0.1033 - val_accuracy: 0.9548\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 118s 211ms/step - loss: 0.1511 - accuracy: 0.9385 - val_loss: 0.1036 - val_accuracy: 0.9549\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 120s 216ms/step - loss: 0.1475 - accuracy: 0.9396 - val_loss: 0.1036 - val_accuracy: 0.9549\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 130s 233ms/step - loss: 0.1464 - accuracy: 0.9401 - val_loss: 0.0896 - val_accuracy: 0.9604\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 91s 163ms/step - loss: 0.1446 - accuracy: 0.9412 - val_loss: 0.0861 - val_accuracy: 0.9624\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 155s 278ms/step - loss: 0.1414 - accuracy: 0.9424 - val_loss: 0.0848 - val_accuracy: 0.9634\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 130s 234ms/step - loss: 0.1390 - accuracy: 0.9441 - val_loss: 0.0838 - val_accuracy: 0.9642\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 115s 208ms/step - loss: 0.1366 - accuracy: 0.9451 - val_loss: 0.0835 - val_accuracy: 0.9643\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 111s 200ms/step - loss: 0.1348 - accuracy: 0.9454 - val_loss: 0.0837 - val_accuracy: 0.9649\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 110s 197ms/step - loss: 0.1331 - accuracy: 0.9459 - val_loss: 0.0841 - val_accuracy: 0.9649\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 116s 208ms/step - loss: 0.1312 - accuracy: 0.9465 - val_loss: 0.0861 - val_accuracy: 0.9642\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 99s 178ms/step - loss: 0.1300 - accuracy: 0.9467 - val_loss: 0.0867 - val_accuracy: 0.9639\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 83s 150ms/step - loss: 0.1281 - accuracy: 0.9480 - val_loss: 0.0866 - val_accuracy: 0.9640\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 84s 151ms/step - loss: 0.1266 - accuracy: 0.9498 - val_loss: 0.0833 - val_accuracy: 0.9656\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "bi_lstm_3 = train_bi_lstm(train_data, test_data, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = bi_lstm_3.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['bi-LSTM']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "bi_lstm_1 = train_bi_lstm(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = bi_lstm_1.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['bi-LSTM']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #5 Convolutional + bidirectional recurrent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_conv_bi_rnn(train_data, test_data, name):\n",
    "    '''\n",
    "    Creates an convolutional + bidirectional RNN network and fits it to supplied data. \n",
    "    Returns fitted model.\n",
    "    Name specifies filename of model saved at checkpoints.\n",
    "    '''\n",
    "    # specify architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv1D(filters = 30, kernel_size = 4, strides = 1, padding = 'same', input_shape = [None, 99]),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.Bidirectional(keras.layers.GRU(units = 30, return_sequences = True), input_shape = [None, 99]),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.Bidirectional(keras.layers.GRU(units = 30)),\n",
    "        keras.layers.Dropout(rate = 0.15),\n",
    "        keras.layers.Dense(units = 1, activation = 'sigmoid')\n",
    "    ])\n",
    "    # compile model\n",
    "    optimizer = keras.optimizers.SGD(momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    # callbacks\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience = 5)\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model_checkpoints/' + 'conv_bi_rnn_' + name + '.h5', save_best_only = True, save_weights_only = False)\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(x = train_data, epochs = 50, validation_data = test_data, callbacks = [lr_scheduler, checkpoint_cb, early_stopping_cb])\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 74s 133ms/step - loss: 0.2333 - accuracy: 0.9166 - val_loss: 2.1449 - val_accuracy: 0.5101\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 55s 98ms/step - loss: 0.2090 - accuracy: 0.9274 - val_loss: 1.9076 - val_accuracy: 0.5008\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 64s 116ms/step - loss: 0.2036 - accuracy: 0.9289 - val_loss: 2.5459 - val_accuracy: 0.4754\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.1963 - accuracy: 0.9314 - val_loss: 2.6811 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.2007 - accuracy: 0.9313 - val_loss: 2.9030 - val_accuracy: 0.4866\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.2100 - accuracy: 0.9295 - val_loss: 2.9851 - val_accuracy: 0.4799\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 58s 105ms/step - loss: 0.1953 - accuracy: 0.9345 - val_loss: 2.8983 - val_accuracy: 0.4753\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.2468 - accuracy: 0.9037 - val_loss: 1.1927 - val_accuracy: 0.5132\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 60s 108ms/step - loss: 0.2204 - accuracy: 0.9084 - val_loss: 1.2921 - val_accuracy: 0.5032\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 67s 120ms/step - loss: 0.2061 - accuracy: 0.9140 - val_loss: 1.2087 - val_accuracy: 0.5172\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.2045 - accuracy: 0.9126 - val_loss: 1.1589 - val_accuracy: 0.5226\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.1920 - accuracy: 0.9165 - val_loss: 1.2417 - val_accuracy: 0.5342\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 61s 110ms/step - loss: 0.1886 - accuracy: 0.9162 - val_loss: 1.2652 - val_accuracy: 0.5392\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.1784 - accuracy: 0.9190 - val_loss: 1.2412 - val_accuracy: 0.5443\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 45s 80ms/step - loss: 0.1669 - accuracy: 0.9231 - val_loss: 1.2354 - val_accuracy: 0.5475\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.1565 - accuracy: 0.9269 - val_loss: 1.2106 - val_accuracy: 0.5553\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 46s 82ms/step - loss: 0.1415 - accuracy: 0.9372 - val_loss: 1.0968 - val_accuracy: 0.5869\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 44s 79ms/step - loss: 0.1288 - accuracy: 0.9430 - val_loss: 1.1309 - val_accuracy: 0.5851\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.1245 - accuracy: 0.9457 - val_loss: 1.1456 - val_accuracy: 0.5866\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.1207 - accuracy: 0.9474 - val_loss: 1.1557 - val_accuracy: 0.5886\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.1164 - accuracy: 0.9491 - val_loss: 1.1700 - val_accuracy: 0.5910\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 55s 98ms/step - loss: 0.1129 - accuracy: 0.9510 - val_loss: 1.1826 - val_accuracy: 0.5933\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 55s 99ms/step - loss: 0.1068 - accuracy: 0.9538 - val_loss: 1.1825 - val_accuracy: 0.6053\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.1034 - accuracy: 0.9555 - val_loss: 1.1946 - val_accuracy: 0.6072\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.1025 - accuracy: 0.9550 - val_loss: 1.2054 - val_accuracy: 0.6089\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.1007 - accuracy: 0.9562 - val_loss: 1.2083 - val_accuracy: 0.6106\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.0997 - accuracy: 0.9573 - val_loss: 1.2149 - val_accuracy: 0.6102\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.0952 - accuracy: 0.9589 - val_loss: 1.2242 - val_accuracy: 0.6118\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.0935 - accuracy: 0.9595 - val_loss: 1.2286 - val_accuracy: 0.6113\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.0931 - accuracy: 0.9600 - val_loss: 1.2354 - val_accuracy: 0.6126\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.0916 - accuracy: 0.9609 - val_loss: 1.2407 - val_accuracy: 0.6124\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.0903 - accuracy: 0.9619 - val_loss: 1.2455 - val_accuracy: 0.6137\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_1_indices, test_1_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_bi_rnn_1 = train_conv_bi_rnn(train_data, test_data, 'fold_1')\n",
    "# predict labels\n",
    "pred_prob = conv_bi_rnn_1.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['convolutional + bidirectional rnn']\n",
    "fold += [1]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 48s 85ms/step - loss: 0.3021 - accuracy: 0.8669 - val_loss: 1.3384 - val_accuracy: 0.5603\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 46s 82ms/step - loss: 0.3050 - accuracy: 0.8713 - val_loss: 1.3912 - val_accuracy: 0.5816\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 46s 82ms/step - loss: 0.2930 - accuracy: 0.8779 - val_loss: 1.2276 - val_accuracy: 0.5850\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.2827 - accuracy: 0.8825 - val_loss: 1.2825 - val_accuracy: 0.6035\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 54s 97ms/step - loss: 0.2748 - accuracy: 0.8857 - val_loss: 1.3199 - val_accuracy: 0.6146\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.2703 - accuracy: 0.8858 - val_loss: 1.2872 - val_accuracy: 0.6157\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 43s 78ms/step - loss: 0.2641 - accuracy: 0.8888 - val_loss: 1.2744 - val_accuracy: 0.6381\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 43s 78ms/step - loss: 0.2610 - accuracy: 0.8904 - val_loss: 1.1885 - val_accuracy: 0.6765\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.2556 - accuracy: 0.8934 - val_loss: 1.1323 - val_accuracy: 0.6829\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 41s 73ms/step - loss: 0.2545 - accuracy: 0.8948 - val_loss: 1.0868 - val_accuracy: 0.6875\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 44s 79ms/step - loss: 0.2534 - accuracy: 0.8948 - val_loss: 0.9948 - val_accuracy: 0.6971\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 44s 79ms/step - loss: 0.2499 - accuracy: 0.8941 - val_loss: 0.9197 - val_accuracy: 0.7059\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.2515 - accuracy: 0.8934 - val_loss: 0.8974 - val_accuracy: 0.7122\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 44s 78ms/step - loss: 0.2474 - accuracy: 0.8946 - val_loss: 0.9474 - val_accuracy: 0.7053\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.2407 - accuracy: 0.8977 - val_loss: 0.9719 - val_accuracy: 0.7081\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.2374 - accuracy: 0.8984 - val_loss: 0.9165 - val_accuracy: 0.7209\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.2331 - accuracy: 0.8995 - val_loss: 0.8812 - val_accuracy: 0.7263\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 43s 78ms/step - loss: 0.2269 - accuracy: 0.9010 - val_loss: 0.8911 - val_accuracy: 0.7299\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.2248 - accuracy: 0.9008 - val_loss: 0.8730 - val_accuracy: 0.7268\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 45s 81ms/step - loss: 0.2233 - accuracy: 0.8996 - val_loss: 0.8715 - val_accuracy: 0.7259\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 45s 81ms/step - loss: 0.2201 - accuracy: 0.9017 - val_loss: 0.8422 - val_accuracy: 0.7325\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 45s 80ms/step - loss: 0.2187 - accuracy: 0.9021 - val_loss: 0.8535 - val_accuracy: 0.7312\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.2122 - accuracy: 0.9049 - val_loss: 0.8494 - val_accuracy: 0.7302\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 53s 94ms/step - loss: 0.2080 - accuracy: 0.9073 - val_loss: 0.8335 - val_accuracy: 0.7340\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.2004 - accuracy: 0.9113 - val_loss: 0.8498 - val_accuracy: 0.7337\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.1950 - accuracy: 0.9139 - val_loss: 0.8447 - val_accuracy: 0.7375\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.1891 - accuracy: 0.9162 - val_loss: 0.8449 - val_accuracy: 0.7366\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.1838 - accuracy: 0.9203 - val_loss: 0.8512 - val_accuracy: 0.7353\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 45s 82ms/step - loss: 0.1780 - accuracy: 0.9217 - val_loss: 0.8638 - val_accuracy: 0.7368\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 46s 83ms/step - loss: 0.1805 - accuracy: 0.9201 - val_loss: 0.7712 - val_accuracy: 0.7443\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.1754 - accuracy: 0.9221 - val_loss: 0.7696 - val_accuracy: 0.7478\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 43s 77ms/step - loss: 0.1687 - accuracy: 0.9240 - val_loss: 0.7723 - val_accuracy: 0.7501\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.1617 - accuracy: 0.9289 - val_loss: 0.7821 - val_accuracy: 0.7527\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.1571 - accuracy: 0.9307 - val_loss: 0.7879 - val_accuracy: 0.7539\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 43s 77ms/step - loss: 0.1532 - accuracy: 0.9332 - val_loss: 0.8005 - val_accuracy: 0.7522\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.1476 - accuracy: 0.9349 - val_loss: 0.8196 - val_accuracy: 0.7548\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.1471 - accuracy: 0.9355 - val_loss: 0.7826 - val_accuracy: 0.7706\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 49s 88ms/step - loss: 0.1454 - accuracy: 0.9359 - val_loss: 0.7687 - val_accuracy: 0.7734\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.1429 - accuracy: 0.9376 - val_loss: 0.7625 - val_accuracy: 0.7752\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 52s 94ms/step - loss: 0.1394 - accuracy: 0.9394 - val_loss: 0.7670 - val_accuracy: 0.7746\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.1369 - accuracy: 0.9399 - val_loss: 0.7720 - val_accuracy: 0.7775\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 42s 75ms/step - loss: 0.1349 - accuracy: 0.9429 - val_loss: 0.7731 - val_accuracy: 0.7761\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.1330 - accuracy: 0.9421 - val_loss: 0.7749 - val_accuracy: 0.7774\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 44s 80ms/step - loss: 0.1320 - accuracy: 0.9427 - val_loss: 0.7809 - val_accuracy: 0.7766\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.1301 - accuracy: 0.9431 - val_loss: 0.7715 - val_accuracy: 0.7797\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 49s 87ms/step - loss: 0.1271 - accuracy: 0.9454 - val_loss: 0.7657 - val_accuracy: 0.7801\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.1257 - accuracy: 0.9463 - val_loss: 0.7645 - val_accuracy: 0.7805\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 49s 87ms/step - loss: 0.1268 - accuracy: 0.9444 - val_loss: 0.7659 - val_accuracy: 0.7797\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.1247 - accuracy: 0.9466 - val_loss: 0.7656 - val_accuracy: 0.7801\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.1222 - accuracy: 0.9469 - val_loss: 0.7660 - val_accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_2_indices, test_2_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_bi_rnn_2 = train_conv_bi_rnn(train_data, test_data, 'fold_2')\n",
    "# predict labels\n",
    "pred_prob = conv_bi_rnn_2.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['convolutional + bidirectional rnn']\n",
    "fold += [2]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fold 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.4948 - accuracy: 0.7646 - val_loss: 1.1998 - val_accuracy: 0.6065\n",
      "Epoch 2/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.4725 - accuracy: 0.7736 - val_loss: 1.5291 - val_accuracy: 0.5020\n",
      "Epoch 3/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.4551 - accuracy: 0.7913 - val_loss: 1.4826 - val_accuracy: 0.3691\n",
      "Epoch 4/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.4311 - accuracy: 0.8011 - val_loss: 1.0729 - val_accuracy: 0.5352\n",
      "Epoch 5/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.8124 - val_accuracy: 0.5581\n",
      "Epoch 6/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.4181 - accuracy: 0.8098 - val_loss: 0.9950 - val_accuracy: 0.5310\n",
      "Epoch 7/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4274 - accuracy: 0.7985 - val_loss: 0.5987 - val_accuracy: 0.7622\n",
      "Epoch 8/50\n",
      "556/556 [==============================] - 57s 103ms/step - loss: 0.4284 - accuracy: 0.8010 - val_loss: 0.3574 - val_accuracy: 0.8722\n",
      "Epoch 9/50\n",
      "556/556 [==============================] - 44s 80ms/step - loss: 0.4242 - accuracy: 0.8034 - val_loss: 0.4077 - val_accuracy: 0.8427\n",
      "Epoch 10/50\n",
      "556/556 [==============================] - 46s 82ms/step - loss: 0.4233 - accuracy: 0.8085 - val_loss: 0.3928 - val_accuracy: 0.8478\n",
      "Epoch 11/50\n",
      "556/556 [==============================] - 54s 96ms/step - loss: 0.4148 - accuracy: 0.8140 - val_loss: 0.4936 - val_accuracy: 0.7861\n",
      "Epoch 12/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.3986 - accuracy: 0.8213 - val_loss: 0.4772 - val_accuracy: 0.7895\n",
      "Epoch 13/50\n",
      "556/556 [==============================] - 45s 81ms/step - loss: 0.3989 - accuracy: 0.8205 - val_loss: 0.5153 - val_accuracy: 0.7896\n",
      "Epoch 14/50\n",
      "556/556 [==============================] - 44s 80ms/step - loss: 0.4380 - accuracy: 0.7982 - val_loss: 0.2785 - val_accuracy: 0.8787\n",
      "Epoch 15/50\n",
      "556/556 [==============================] - 44s 80ms/step - loss: 0.4354 - accuracy: 0.7945 - val_loss: 0.3148 - val_accuracy: 0.8604\n",
      "Epoch 16/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4212 - accuracy: 0.8035 - val_loss: 0.3088 - val_accuracy: 0.8539\n",
      "Epoch 17/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4153 - accuracy: 0.8089 - val_loss: 0.2457 - val_accuracy: 0.8859\n",
      "Epoch 18/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.4114 - accuracy: 0.8137 - val_loss: 0.2562 - val_accuracy: 0.8796\n",
      "Epoch 19/50\n",
      "556/556 [==============================] - 50s 90ms/step - loss: 0.4046 - accuracy: 0.8169 - val_loss: 0.3279 - val_accuracy: 0.8424\n",
      "Epoch 20/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.3991 - accuracy: 0.8199 - val_loss: 0.3240 - val_accuracy: 0.8426\n",
      "Epoch 21/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.3991 - accuracy: 0.8190 - val_loss: 0.2709 - val_accuracy: 0.8705\n",
      "Epoch 22/50\n",
      "556/556 [==============================] - 51s 91ms/step - loss: 0.3966 - accuracy: 0.8205 - val_loss: 0.2286 - val_accuracy: 0.8997\n",
      "Epoch 23/50\n",
      "556/556 [==============================] - 50s 91ms/step - loss: 0.3927 - accuracy: 0.8219 - val_loss: 0.2343 - val_accuracy: 0.8994\n",
      "Epoch 24/50\n",
      "556/556 [==============================] - 48s 85ms/step - loss: 0.3885 - accuracy: 0.8232 - val_loss: 0.2642 - val_accuracy: 0.8780\n",
      "Epoch 25/50\n",
      "556/556 [==============================] - 51s 92ms/step - loss: 0.3782 - accuracy: 0.8283 - val_loss: 0.3414 - val_accuracy: 0.8440\n",
      "Epoch 26/50\n",
      "556/556 [==============================] - 49s 89ms/step - loss: 0.3707 - accuracy: 0.8321 - val_loss: 0.4020 - val_accuracy: 0.8207\n",
      "Epoch 27/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.3686 - accuracy: 0.8318 - val_loss: 0.3641 - val_accuracy: 0.8390\n",
      "Epoch 28/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.4057 - accuracy: 0.8156 - val_loss: 0.2692 - val_accuracy: 0.8787\n",
      "Epoch 29/50\n",
      "556/556 [==============================] - 47s 85ms/step - loss: 0.3939 - accuracy: 0.8210 - val_loss: 0.2575 - val_accuracy: 0.8837\n",
      "Epoch 30/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.3835 - accuracy: 0.8268 - val_loss: 0.2430 - val_accuracy: 0.8910\n",
      "Epoch 31/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.3746 - accuracy: 0.8315 - val_loss: 0.2356 - val_accuracy: 0.8948\n",
      "Epoch 32/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.3699 - accuracy: 0.8330 - val_loss: 0.2289 - val_accuracy: 0.8973\n",
      "Epoch 33/50\n",
      "556/556 [==============================] - 48s 87ms/step - loss: 0.3755 - accuracy: 0.8336 - val_loss: 0.1597 - val_accuracy: 0.9251\n",
      "Epoch 34/50\n",
      "556/556 [==============================] - 60s 107ms/step - loss: 0.3651 - accuracy: 0.8366 - val_loss: 0.1500 - val_accuracy: 0.9300\n",
      "Epoch 35/50\n",
      "556/556 [==============================] - 58s 104ms/step - loss: 0.3573 - accuracy: 0.8399 - val_loss: 0.1429 - val_accuracy: 0.9335\n",
      "Epoch 36/50\n",
      "556/556 [==============================] - 47s 84ms/step - loss: 0.3506 - accuracy: 0.8433 - val_loss: 0.1393 - val_accuracy: 0.9350\n",
      "Epoch 37/50\n",
      "556/556 [==============================] - 74s 133ms/step - loss: 0.3461 - accuracy: 0.8450 - val_loss: 0.1381 - val_accuracy: 0.9359\n",
      "Epoch 38/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.3397 - accuracy: 0.8483 - val_loss: 0.1315 - val_accuracy: 0.9382\n",
      "Epoch 39/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.3342 - accuracy: 0.8525 - val_loss: 0.1282 - val_accuracy: 0.9401\n",
      "Epoch 40/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.3310 - accuracy: 0.8522 - val_loss: 0.1264 - val_accuracy: 0.9415\n",
      "Epoch 41/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.3243 - accuracy: 0.8559 - val_loss: 0.1229 - val_accuracy: 0.9428\n",
      "Epoch 42/50\n",
      "556/556 [==============================] - 42s 76ms/step - loss: 0.3213 - accuracy: 0.8555 - val_loss: 0.1233 - val_accuracy: 0.9423\n",
      "Epoch 43/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.3176 - accuracy: 0.8588 - val_loss: 0.1224 - val_accuracy: 0.9432\n",
      "Epoch 44/50\n",
      "556/556 [==============================] - 41s 74ms/step - loss: 0.3154 - accuracy: 0.8600 - val_loss: 0.1207 - val_accuracy: 0.9439\n",
      "Epoch 45/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.3099 - accuracy: 0.8626 - val_loss: 0.1187 - val_accuracy: 0.9448\n",
      "Epoch 46/50\n",
      "556/556 [==============================] - 53s 95ms/step - loss: 0.3080 - accuracy: 0.8641 - val_loss: 0.1191 - val_accuracy: 0.9443\n",
      "Epoch 47/50\n",
      "556/556 [==============================] - 50s 89ms/step - loss: 0.3022 - accuracy: 0.8664 - val_loss: 0.1185 - val_accuracy: 0.9450\n",
      "Epoch 48/50\n",
      "556/556 [==============================] - 48s 86ms/step - loss: 0.2994 - accuracy: 0.8690 - val_loss: 0.1165 - val_accuracy: 0.9453\n",
      "Epoch 49/50\n",
      "556/556 [==============================] - 53s 96ms/step - loss: 0.2972 - accuracy: 0.8682 - val_loss: 0.1183 - val_accuracy: 0.9449\n",
      "Epoch 50/50\n",
      "556/556 [==============================] - 52s 93ms/step - loss: 0.2929 - accuracy: 0.8701 - val_loss: 0.1160 - val_accuracy: 0.9462\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X_train, X_test, y_train, y_test = data_for_modeling(train_3_indices, test_3_indices, sequence = True)\n",
    "train_data = timeseries_dataset_from_array(data = X_train, targets = y_train, sequence_length = 20, sequence_stride = 5)\n",
    "test_data = timeseries_dataset_from_array(data = X_test, targets = y_test, sequence_length = 20, sequence_stride = 20)\n",
    "# fit model\n",
    "conv_bi_rnn_3 = train_conv_bi_rnn(train_data, test_data, 'fold_3')\n",
    "# predict labels\n",
    "pred_prob = conv_bi_rnn_3.predict(test_data)\n",
    "pred = np.array([1 if prob >= 0.5 else 0 for prob in pred_prob])\n",
    "y_test = format_test(y_test)\n",
    "# record results\n",
    "model += ['convolutional + bidirectional rnn']\n",
    "fold += [3]\n",
    "accuracy += [accuracy_score(y_test, pred)]\n",
    "precision_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][1]]\n",
    "precision_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[0][0]]\n",
    "recall_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][1]]\n",
    "recall_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[1][0]]\n",
    "support_sober += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][0]]\n",
    "support_intox += [precision_recall_fscore_support(y_test, pred, zero_division = 1)[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['Bi-LSTM','Bi-LSTM','Bi-LSTM','Conv+Bi-GRU','Conv+Bi-GRU','Conv+Bi-GRU','LSTM','LSTM','LSTM','Conv+GRU','Conv+GRU','Conv+GRU','Wavenet','Wavenet','Wavenet']\n",
    "fold = [1,2,3,1,2,3,1,2,3,1,2,3,1,2,3]\n",
    "accuracy = [0.518848,0.775065,0.965568,0.586925,0.779003,0.946214,0.510183,0.756836,0.965230,0.571621,0.740407,0.960729,0.543828,0.720266,1.000000]\n",
    "precision_intox = [0.483556,0.594563,0,0.545261,0.623229,0,0.477623,0.556719,0,0.525354,0.527146,0,1,1,1]\n",
    "precision_sober =[0.630323,0.848701,1,0.624785,0.827744,1,0.608794,0.852043,1,0.627739,0.866190,1,0.543828,0.720266,1]\n",
    "recall_intox = [0.805131,0.615849,1,0.569068,0.530973,1,0.787124,0.641593,1,0.631228,0.699115,1,0,0,1]\n",
    "recall_sober = [0.278709,0.836900,0.965568,0.601904,0.875332,0.946214,0.277881,0.801594,0.965230,0.521622,0.756444,0.960729,1,1,1]\n",
    "support_sober = [4833,6401,8887,4833,6401,8887,4833,6401,8887,4833,6401,8887,4833,6401,8887]\n",
    "support_intox = [4054,2486,0,4054,2486,0,4054,2486,0,4054,2486,0,4054,2486,0]\n",
    "\n",
    "results = {'model':model,'fold':fold,'accuracy':accuracy,'precision (intoxicated)':precision_intox,'precision (sober)':precision_sober,'recall (intoxicated)':recall_intox,\n",
    "          'recall (sober)':recall_sober, 'support (sober)':support_sober, 'support (intoxicated)':support_intox}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision (intoxicated)</th>\n",
       "      <th>precision (sober)</th>\n",
       "      <th>recall (intoxicated)</th>\n",
       "      <th>recall (sober)</th>\n",
       "      <th>support (sober)</th>\n",
       "      <th>support (intoxicated)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518848</td>\n",
       "      <td>0.483556</td>\n",
       "      <td>0.630323</td>\n",
       "      <td>0.805131</td>\n",
       "      <td>0.278709</td>\n",
       "      <td>4833</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775065</td>\n",
       "      <td>0.594563</td>\n",
       "      <td>0.848701</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>0.836900</td>\n",
       "      <td>6401</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965568</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conv+Bi-GRU</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586925</td>\n",
       "      <td>0.545261</td>\n",
       "      <td>0.624785</td>\n",
       "      <td>0.569068</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>4833</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conv+Bi-GRU</td>\n",
       "      <td>2</td>\n",
       "      <td>0.779003</td>\n",
       "      <td>0.623229</td>\n",
       "      <td>0.827744</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.875332</td>\n",
       "      <td>6401</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Conv+Bi-GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>0.946214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946214</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510183</td>\n",
       "      <td>0.477623</td>\n",
       "      <td>0.608794</td>\n",
       "      <td>0.787124</td>\n",
       "      <td>0.277881</td>\n",
       "      <td>4833</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.756836</td>\n",
       "      <td>0.556719</td>\n",
       "      <td>0.852043</td>\n",
       "      <td>0.641593</td>\n",
       "      <td>0.801594</td>\n",
       "      <td>6401</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965230</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Conv+GRU</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571621</td>\n",
       "      <td>0.525354</td>\n",
       "      <td>0.627739</td>\n",
       "      <td>0.631228</td>\n",
       "      <td>0.521622</td>\n",
       "      <td>4833</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Conv+GRU</td>\n",
       "      <td>2</td>\n",
       "      <td>0.740407</td>\n",
       "      <td>0.527146</td>\n",
       "      <td>0.866190</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>0.756444</td>\n",
       "      <td>6401</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Conv+GRU</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960729</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wavenet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.543828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.543828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4833</td>\n",
       "      <td>4054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wavenet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.720266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6401</td>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wavenet</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  fold  accuracy  precision (intoxicated)  precision (sober)  \\\n",
       "0       Bi-LSTM     1  0.518848                 0.483556           0.630323   \n",
       "1       Bi-LSTM     2  0.775065                 0.594563           0.848701   \n",
       "2       Bi-LSTM     3  0.965568                 0.000000           1.000000   \n",
       "3   Conv+Bi-GRU     1  0.586925                 0.545261           0.624785   \n",
       "4   Conv+Bi-GRU     2  0.779003                 0.623229           0.827744   \n",
       "5   Conv+Bi-GRU     3  0.946214                 0.000000           1.000000   \n",
       "6          LSTM     1  0.510183                 0.477623           0.608794   \n",
       "7          LSTM     2  0.756836                 0.556719           0.852043   \n",
       "8          LSTM     3  0.965230                 0.000000           1.000000   \n",
       "9      Conv+GRU     1  0.571621                 0.525354           0.627739   \n",
       "10     Conv+GRU     2  0.740407                 0.527146           0.866190   \n",
       "11     Conv+GRU     3  0.960729                 0.000000           1.000000   \n",
       "12      Wavenet     1  0.543828                 1.000000           0.543828   \n",
       "13      Wavenet     2  0.720266                 1.000000           0.720266   \n",
       "14      Wavenet     3  1.000000                 1.000000           1.000000   \n",
       "\n",
       "    recall (intoxicated)  recall (sober)  support (sober)  \\\n",
       "0               0.805131        0.278709             4833   \n",
       "1               0.615849        0.836900             6401   \n",
       "2               1.000000        0.965568             8887   \n",
       "3               0.569068        0.601904             4833   \n",
       "4               0.530973        0.875332             6401   \n",
       "5               1.000000        0.946214             8887   \n",
       "6               0.787124        0.277881             4833   \n",
       "7               0.641593        0.801594             6401   \n",
       "8               1.000000        0.965230             8887   \n",
       "9               0.631228        0.521622             4833   \n",
       "10              0.699115        0.756444             6401   \n",
       "11              1.000000        0.960729             8887   \n",
       "12              0.000000        1.000000             4833   \n",
       "13              0.000000        1.000000             6401   \n",
       "14              1.000000        1.000000             8887   \n",
       "\n",
       "    support (intoxicated)  \n",
       "0                    4054  \n",
       "1                    2486  \n",
       "2                       0  \n",
       "3                    4054  \n",
       "4                    2486  \n",
       "5                       0  \n",
       "6                    4054  \n",
       "7                    2486  \n",
       "8                       0  \n",
       "9                    4054  \n",
       "10                   2486  \n",
       "11                      0  \n",
       "12                   4054  \n",
       "13                   2486  \n",
       "14                      0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision (intoxicated)</th>\n",
       "      <th>precision (sober)</th>\n",
       "      <th>recall (intoxicated)</th>\n",
       "      <th>recall (sober)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-LSTM</td>\n",
       "      <td>0.753160</td>\n",
       "      <td>0.359373</td>\n",
       "      <td>0.826341</td>\n",
       "      <td>0.806993</td>\n",
       "      <td>0.693726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conv+Bi-GRU</td>\n",
       "      <td>0.770714</td>\n",
       "      <td>0.389497</td>\n",
       "      <td>0.817510</td>\n",
       "      <td>0.700014</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conv+GRU</td>\n",
       "      <td>0.757586</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.831310</td>\n",
       "      <td>0.776781</td>\n",
       "      <td>0.746265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.744083</td>\n",
       "      <td>0.344781</td>\n",
       "      <td>0.820279</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.681568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wavenet</td>\n",
       "      <td>0.754698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754698</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  accuracy  precision (intoxicated)  precision (sober)  \\\n",
       "0      Bi-LSTM  0.753160                 0.359373           0.826341   \n",
       "1  Conv+Bi-GRU  0.770714                 0.389497           0.817510   \n",
       "2     Conv+GRU  0.757586                 0.350833           0.831310   \n",
       "3         LSTM  0.744083                 0.344781           0.820279   \n",
       "4      Wavenet  0.754698                 1.000000           0.754698   \n",
       "\n",
       "   recall (intoxicated)  recall (sober)  \n",
       "0              0.806993        0.693726  \n",
       "1              0.700014        0.807817  \n",
       "2              0.776781        0.746265  \n",
       "3              0.809572        0.681568  \n",
       "4              0.333333        1.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).groupby('model', as_index = False).agg(np.mean).drop(['fold', 'support (sober)', 'support (intoxicated)'], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
